{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data preparation utilities\n",
    "> Functions that prepare label files and split the data into train validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "# default_exp dataprep_utils\n",
    "from cellsegment.core import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "import random\n",
    "from  cellsegment.core import *\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import pandas\n",
    "from fastai.vision import get_image_files, parallel, partial, PIL, Path, get_files\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.color import label2rgb\n",
    "from skimage.exposure import histogram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "\n",
    "LABELS = [\n",
    "        {'Name': 'Fluke, Liver', 'Code': '11', 'Fill': (255, 0, 0, 64)},\n",
    "        {'Name': 'Fluke, Rumen', 'Code': '40', 'Fill': (0, 255, 0, 64)},\n",
    "        {'Name': 'Other', 'Code': '', 'Fill': (255, 255, 0, 64)},\n",
    "    ]\n",
    "\n",
    "FILENAME_TRIM = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def createjson(fn='', offset=0):\n",
    "    'create a Labelme compatable json file'\n",
    "    data = {\n",
    "        'version': '3.13.1',\n",
    "        'flags': {},\n",
    "        'shapes': [],\n",
    "        'lineColor': [0, 255, 0, 255],\n",
    "        'fillColor': [255, 255, 0, 20],\n",
    "        'imagePath': fn,\n",
    "        'offset': offset,\n",
    "        'imageData': None,\n",
    "        'imageHeight': 2464,\n",
    "        'imageWidth': 2464}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see lableme at https://github.com/wkentaro/labelme/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def annotate_json(data, shape_type='circle', points=None):\n",
    "    # Annotate the json file with list of points\n",
    "    assert shape_type == 'point' or shape_type == 'circle' or shape_type == 'rectangle'\n",
    "\n",
    "    def add_anno(data, item):\n",
    "        cx, cy = item['point']\n",
    "        pnt_list = []\n",
    "        if shape_type == 'point':\n",
    "            pnt_list = [[cx, cy]]\n",
    "        elif shape_type == 'rectangle':  # bounding points\n",
    "            r = 40\n",
    "            pnt_list = [[cx - r, cy - r], [cx + r, cy + r]]\n",
    "        elif shape_type == 'circle':   # center & radius\n",
    "            r = 20\n",
    "            pnt_list = [[cx, cy], [cx + r, cy + r]]\n",
    "\n",
    "        probability = str(item['probability']) if 'probability' in item else str(0)\n",
    "\n",
    "        if item['label'] == 1:\n",
    "            line_color = [255, 0, 0, 127]\n",
    "            data['shapes'].append({\n",
    "                \"label\": str(item['label']), \"line_color\": [255, 0, 0, 127], \"fill_color\": [255, 0, 0, 127],\n",
    "                \"points\": pnt_list, \"shape_type\": shape_type, 'probability': probability\n",
    "            })\n",
    "\n",
    "        elif item['label'] == 2:\n",
    "            line_color = [0, 255, 0, 127]\n",
    "            data['shapes'].append({\n",
    "                \"label\": str(item['label']), \"line_color\": [0, 255, 0, 127], \"fill_color\": [0, 255, 0, 127],\n",
    "                \"points\": pnt_list, \"shape_type\": shape_type, 'probability': probability\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            line_color = [0, 0, 255, 127]\n",
    "            data['shapes'].append({\n",
    "                \"label\": str(item['label']), \"line_color\": [0, 0, 255, 127], \"fill_color\": [0, 0, 255, 127],\n",
    "                \"points\": pnt_list, \"shape_type\": shape_type, 'probability': probability\n",
    "            })\n",
    "\n",
    "    def add_annotations(data, points):\n",
    "        for item in points:\n",
    "            add_anno(data, item)\n",
    "\n",
    "    add_annotations(data, points)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def __create_json_from_CSV(csv_fn, load_jpg_fn, offset=0, height=0, width=0):\n",
    "    # Annotate the json file with predictions\n",
    "    data = {\n",
    "        'version': '3.13.1',\n",
    "        'flags': {},\n",
    "        'shapes': [],\n",
    "        'lineColor': [0, 255, 0, 255],\n",
    "        'fillColor': [255, 255, 0, 20],\n",
    "        'imagePath': load_jpg_fn,\n",
    "        'offset': offset,\n",
    "        'imageData': None,\n",
    "        'imageHeight': height,\n",
    "        'imageWidth': width}\n",
    "\n",
    "    # species_name = ['Nematodirus', 'Strongyle', 'other']\n",
    "\n",
    "    egg_centers = []\n",
    "    with open(csv_fn, mode='r') as f:\n",
    "        line_count = 0\n",
    "        for line in f:\n",
    "            row, col, species = [int(x) for x in line.split(',')]\n",
    "            egg_centers.append({\"label\": species, \"particleType\": species, \"point\": [row, col]})\n",
    "            line_count += 1\n",
    "\n",
    "    data = annotate_json(data, points=egg_centers)\n",
    "    data\n",
    "    return data\n",
    "\n",
    "def csv_to_json_dir(src_path, dest_path, number_files='all'):\n",
    "    \"\"\" Convert an entire directory of Techion CSV files to JSON files. Store in the dest directory\n",
    "    CSV format is x,y,species_number\n",
    "    1383,1571,2\n",
    "    1687,1822,1\n",
    "    2036,1327,1\n",
    "    \"\"\"\n",
    "    print('Converting an entire directory of Techion CSV files to JSON files')\n",
    "    fnames_csv = sorted(get_files(src_path, extensions=['.csv']))\n",
    "    fnames_jpg = sorted(get_files(src_path, extensions=['.jpg']))\n",
    "    if isinstance(number_files, int):\n",
    "        fnames_csv = fnames_csv[:number_files]\n",
    "        fnames_jpg = fnames_jpg[:number_files]\n",
    "    print('Number of csv & jpg files to convert', len(fnames_csv), len(fnames_jpg))\n",
    "\n",
    "    Path(dest_path).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"src_path {src_path}\")\n",
    "    print(f\"dest_path {dest_path}\")\n",
    "\n",
    "    for i,fn in enumerate(fnames_csv):\n",
    "        parent = Path(fn).parents[0]\n",
    "        name = Path(fn).name.split('.')[0]\n",
    "        jpg_fn = f\"{parent}/{name}.jpg\"\n",
    "        json_fn = f\"{parent}/{name}.json\"\n",
    "\n",
    "        if Path(jpg_fn).is_file():\n",
    "            img = PIL.Image.open(jpg_fn)\n",
    "            data = __create_json_from_CSV(fn, Path(jpg_fn).name, height=img.size[1], width=img.size[0])\n",
    "            with open(json_fn, 'w') as outfile:\n",
    "                # json.dump(data, outfile, indent=2)\n",
    "                # print(f'Saving File {json_fn}')\n",
    "                json.dump(data, outfile, ensure_ascii=False, indent=4)\n",
    "                progress_bar(i+1,50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def crop2well(img, thres_adjust=1., bg_color=[0,0,0], op='crop'):\n",
    "    '''Returns a square colour and gray image centered on the well with width same as the height.\n",
    "    thres_adjust is  optional otsu threshold scaling multiplier\n",
    "    Also returns the offset to the original image and the well region properties'''\n",
    "    assert op=='mask' or op=='crop', 'op must be either \"mask\" or \"crop\"), the value was {}'.format(op)\n",
    "\n",
    "    width = img.shape[0]\n",
    "    img_gray = rgb2gray(img)\n",
    "    thresh = threshold_otsu(img_gray)\n",
    "    img_thresholded = closing(img_gray > thresh * thres_adjust, square(3))\n",
    "    label_image = label(img_thresholded)\n",
    "\n",
    "    well_region = None\n",
    "    for region in regionprops(label_image):\n",
    "        if region.area >= 100000:\n",
    "            well_region = region\n",
    "    # if region_center == 0: raise ValueError('No region_center found')\n",
    "\n",
    "    r0, c0, r1, c1 = well_region.bbox\n",
    "    if op=='mask':\n",
    "        well_circle_mask = pad(well_region.convex_image, (img.shape[:2]), well_region.bbox[:2])\n",
    "        img_crop = img[r0:r1, c0:c1]\n",
    "        img_rgb = pad(img_crop, img.shape, well_region.bbox[:2], bg_color=bg_color)\n",
    "        return img_rgb, img_thresholded, well_circle_mask, well_region\n",
    "    elif op=='crop':\n",
    "        well_center = (c0 + c1)//2\n",
    "        offset = well_center - width//2\n",
    "        img_rgb = img[:, offset:well_center + width//2, :]\n",
    "        return img_rgb, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def well_circle_mask(img, well_regionprops):\n",
    "    return pad(well_regionprops.convex_image, (img.shape[:2]), well_regionprops.bbox[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def check_well_crop(img, well_regionprops):\n",
    "    assert img.shape[0] == img.shape[1], \"Expecting the cropped  well image to be square\"\n",
    "    bbox = well_regionprops.bbox\n",
    "    bbox_area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "    bbox_squareness = (bbox[2] - bbox[0]) / (bbox[3] - bbox[1])\n",
    "    bbox_percent = bbox_area / (img.shape[0] * img.shape[0])\n",
    "    max_well_area = 3.14156 * img.shape[0] * img.shape[0] / 4\n",
    "    illum_well_percent = well_regionprops.area / max_well_area\n",
    "\n",
    "    print('bbox_percent', bbox_percent)\n",
    "    print('bbox_squareness', bbox_squareness)\n",
    "    print('illum_well_percent', illum_well_percent)\n",
    "    print('illum_well_saturation', illum_well_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def pad(im, shape, offset, bg_color=None):\n",
    "    \"\"\"\n",
    "    array: Array to be padded\n",
    "    reference_shape: tuple of size of ndarray to create\n",
    "    offsets: list of offsets (number of elements must be equal to the dimension of the array)\n",
    "    will throw a ValueError if offsets is too big and the reference_shape cannot handle the offsets\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an array of zeros with the reference shape\n",
    "    if bg_color:\n",
    "        result = np.ones(shape, im.dtype)\n",
    "        result = result * np.array(bg_color)\n",
    "    else:\n",
    "        result = np.zeros(shape, im.dtype)\n",
    "    # Create a list of slices from offset to offset + shape in each dimension\n",
    "    insertHere = [slice(offset[dim], offset[dim] + im.shape[dim]) for dim in range(2)]\n",
    "    # Insert the array in the result at the specified offsets\n",
    "    result[insertHere] = im\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def get_image_size(fn):\n",
    "    return PIL.Image.open(fn).size\n",
    "\n",
    "\n",
    "def resize_crop2well_one(fn, i, src_path, dest_path, height):\n",
    "    img = PIL.Image.open(src_path / fn.name)\n",
    "    img_w, img_h = img.size\n",
    "    scale = float(height / img_h)\n",
    "    shape = (int(img_w * scale), height)\n",
    "    img_cropped, offset = crop2well(np.asarray(img.resize(shape)))\n",
    "    img_cropped = PIL.Image.fromarray(img_cropped.astype('uint8'), 'RGB')\n",
    "    img_cropped.save(dest_path / f'{fn.stem}|{scale:.6f}|{offset:3}|.jpg', quality=90)\n",
    "\n",
    "# def resize_crop2center_one(fn, i, src_path, dest_path, height):\n",
    "#     img = PIL.Image.open(src_path / fn.name)\n",
    "#     img_w, img_h = img.size\n",
    "#     scale = float(height / img_h)\n",
    "#     shape = (int(img_w * scale), height)\n",
    "#     img_cropped, offset = crop2well(np.asarray(img.resize(shape)))\n",
    "#     img_cropped = PIL.Image.fromarray(img_cropped.astype('uint8'), 'RGB')\n",
    "#     img_cropped.save(dest_path / f'{fn.stem}|{scale:.6f}|{offset:3}|.jpg', quality=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "DEFAULT_LABEL_FILL = (255, 255, 255, 64)\n",
    "def label_from_json(data, img, plot=False, radius=20):\n",
    "    # data = json.load(open(load_json_fn(fn)))\n",
    "    # img = PIL.Image.open(load_img_fn(fn))\n",
    "    num_points = 0\n",
    "    label_cnt_list = [{ 'Name': lab['Name'], 'Code': lab['Code'], 'Count': 0 } for lab in LABELS]\n",
    "    for s, sh in enumerate(data['shapes']):\n",
    "        fill = DEFAULT_LABEL_FILL\n",
    "        for i, label in enumerate(LABELS):\n",
    "            if sh[\"shape_type\"] == \"circle\":\n",
    "                if sh[\"label\"] == label['Code']:\n",
    "                    fill = label['Fill']\n",
    "                    label_cnt_list[i]['Count'] += 1\n",
    "                    num_points += 1\n",
    "                    break\n",
    "\n",
    "        # draw a circle at the circle\n",
    "        if sh[\"shape_type\"] == \"circle\":\n",
    "            xy = np.asarray(sh[\"points\"])\n",
    "            # ave = np.mean(xy, axis=0)\n",
    "            # cx, cy = ave[0], ave[1]\n",
    "            cx, cy = xy[0][0], xy[0][1]\n",
    "            draw = PIL.ImageDraw.Draw(img)\n",
    "\n",
    "            draw.ellipse([cx - radius, cy - radius, cx + radius, cy + radius], outline=0, fill=fill)\n",
    "            num_points += 1\n",
    "\n",
    "    img = np.asarray(img)\n",
    "\n",
    "    return img, num_points, label_cnt_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def create_one_label(fn, i, json_path, lab_path, colormap):\n",
    "    data = json.load(open(f'{json_path}/{fn.stem}.json'))\n",
    "    # img = PIL.Image.open(f'{src_path}/{fn.stem}.jpg')\n",
    "    img = PIL.Image.new('RGB', (data[\"imageWidth\"], data[\"imageHeight\"]), color=(0, 0, 0))\n",
    "    # h = data[\"imageHeight\"]\n",
    "    # w = data[\"imageWidth\"]\n",
    "    img, num_pnts, label_cnt_list = label_from_json(data, img, plot=False, radius=10)\n",
    "    # ToDo: fix this code as it is not extendable\n",
    "    lbl_pil_1 = (img[:, :, 0] >= 200) & (img[:, :, 1] <= 10) & (img[:, :, 2] <= 10)\n",
    "    lbl_pil_2 = (img[:, :, 1] >= 200) & (img[:, :, 0] <= 10) & (img[:, :, 2] <= 10)\n",
    "    lbl_pil = lbl_pil_1 + 2 * lbl_pil_2\n",
    "\n",
    "    lbl_pil = PIL.Image.fromarray(lbl_pil.astype(np.uint8), mode='P')\n",
    "    lbl_pil.putpalette(colormap)\n",
    "    lbl_pil.save(f'{lab_path}/{fn.stem}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def resize_dir(file_data, src_path, dest_path, number_files='all', height=1200):\n",
    "    \"\"\"\n",
    "    Resize  an entire directory. Store in the dest directory\n",
    "    :param src_path:\n",
    "    :param dest_path:\n",
    "    :param number_files:\n",
    "    :param height:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    df = pandas.read_csv(file_data, index_col=0)\n",
    "    __number_files = df.shape[0]\n",
    "\n",
    "    print(f'Number of image files: {__number_files}, Number to resize: {number_files}')\n",
    "    Path(dest_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if isinstance(number_files, int):\n",
    "        __number_files = number_files\n",
    "\n",
    "    for i in range(__number_files):\n",
    "        f_stem = df.loc[i,'Name'].split('.')[0]\n",
    "        scale = float(height) / df.loc[i,'Height']\n",
    "        img = resize_file(f'{src_path}/{f_stem}.jpg', scale=scale)\n",
    "        img.save(f'{dest_path}/{f_stem}.jpg', quality=90)\n",
    "\n",
    "        progress_bar(i + 1, 50)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def resize_json_file(fn, scale=1, offset=0):\n",
    "    data = json.load(open(fn))\n",
    "\n",
    "    for s, sh in enumerate(data['shapes']):\n",
    "        for p, pnt in enumerate(sh[\"points\"]):\n",
    "            data['shapes'][s]['points'][p][0] = round(data['shapes'][s]['points'][p][0] * scale)\n",
    "            data['shapes'][s]['points'][p][1] = round(data['shapes'][s]['points'][p][1] * scale)\n",
    "            data['shapes'][s]['points'][p][0] = data['shapes'][s]['points'][p][0] - offset\n",
    "    data['imageData'] = None\n",
    "    data['offset'] = offset\n",
    "    data['scale'] = scale\n",
    "    data['imageWidth'] = int (data['imageWidth'] * scale)\n",
    "    data['imageHeight'] = int (data['imageHeight'] * scale)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def resize_json_dir(file_data, src_path, dest_path, number_files='all', height=800):\n",
    "    \"\"\"\n",
    "    Resize src_path directory of JSON files and store in dest_path directory\n",
    "    There needs to be resized jpg files in the dest_path directory.\n",
    "    An example is  226260 - 1|0.436047|221|.jpg  where |0.436047|221| marks the factor and offset factors to apply\n",
    "    :param src_path: Source path where json files are\n",
    "    :param dest_path: Destination path to store resized json files\n",
    "    :param number_files: Number of json files to process, leave empty for all files in directory\n",
    "    :return: number of file processed\n",
    "    \"\"\"\n",
    "    df = pandas.read_csv(file_data, index_col=0)\n",
    "    __number_files = df.shape[0]\n",
    "\n",
    "    print(f'Number of JSON files: {__number_files}, Number to resize: {number_files}')\n",
    "    Path(dest_path).mkdir(parents=True, exist_ok=True)\n",
    "    if isinstance(number_files, int):\n",
    "        __number_files = number_files\n",
    "\n",
    "    for i in range(__number_files):\n",
    "        f_stem = df.loc[i,'Name'].split('.')[0]\n",
    "        scale = float(height) / df.loc[i,'Height']\n",
    "        offset = 0\n",
    "        data = resize_json_file(f'{src_path}/{f_stem}.json', scale=float(scale), offset=int(offset))\n",
    "        data['imagePath'] = df.loc[i,'Name']\n",
    "        with open(f'{dest_path}/{f_stem}.json', 'w') as outfile:\n",
    "            json.dump(data, outfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "        progress_bar(i + 1, 50)\n",
    "    print('')\n",
    "    print(i+1, ' json files processed')\n",
    "    return i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def shuffle_csv(file_csv,random_state=None):\n",
    "    df = pandas.read_csv(file_csv, index_col=0)\n",
    "    df = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    df.to_csv(file_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def split_filenames(file_csv, num_train=0.70, num_val=0.15):\n",
    "    \"\"\"\n",
    "    shuffle file names, split into train valid and test and update file_data.csv with labels\n",
    "\n",
    "    :param file_csv: csv file with file names and data\n",
    "    :param num_train:\n",
    "    :param num_val:\n",
    "    :param seed:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df = pandas.read_csv(file_csv, index_col=0)\n",
    "    __number_files = df.shape[0]\n",
    "\n",
    "    # add Op column\n",
    "    operation = ['Train'] * int(__number_files * num_train)\n",
    "    operation = operation + ['Valid'] * int(__number_files * num_val)\n",
    "    operation = operation + ['Test'] * (__number_files - len(operation))\n",
    "\n",
    "    df['Op'] = operation\n",
    "    df.to_csv(file_csv, index=False)\n",
    "\n",
    "    # train_df = df.loc[df['Op'] == 'Train']\n",
    "    # valid_df = df.loc[df['Op'] == 'Valid']\n",
    "    # test_df = df.loc[df['Op'] == 'Test']\n",
    "    # trainfiles = train_df['Name'].tolist()\n",
    "    # validfiles = valid_df['Name'].tolist()\n",
    "    # testfiles = test_df['Name'].tolist()\n",
    "    #\n",
    "    # assert len(trainfiles) + len(validfiles) + len(testfiles) == __number_files, 'The number of train, val and test files do not match the original number'\n",
    "    # print(\n",
    "    #     f'Number of train, val and test files ({len(trainfiles)}, {len(validfiles)}, {len(testfiles)}) == {__number_files}')\n",
    "    #\n",
    "    # return trainfiles, validfiles, testfiles\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def __crop_image(jsonfn, imgfn, dest_path, size=200, op:str='', debug=False):\n",
    "    \"\"\"\n",
    "    Crop an image into multiple sub-tiles centered on each egg\n",
    "    :param jsonfn: JSON file with egg centers\n",
    "    :param imgfn: image to be cropped\n",
    "    :param dest_path: directory to put cropped tiles into\n",
    "    :param size: pixel size of crop\n",
    "    :param filename_trim: remove the scale and offset portions of filename and remove extra spaces, 226260 - 1-0.436047-221-.jpg ->  226260-1.jpg\n",
    "    :return: number of cropped images\n",
    "    \"\"\"\n",
    "    img = np.asarray(PIL.Image.open(imgfn))\n",
    "    data = json.load(open(jsonfn))\n",
    "    suffix = Path(imgfn).suffix\n",
    "    dest_path = Path(dest_path)\n",
    "    imgfn = Path(imgfn).stem\n",
    "    assert suffix == '.jpg' or suffix == '.png', \"image file type must be jpg or png\"\n",
    "    imgShape = img.shape\n",
    "\n",
    "    colormap = colormap_segmentation_labels()\n",
    "    n = 0\n",
    "    croplist = []\n",
    "    for n, sh in enumerate(data['shapes']):\n",
    "        if sh[\"shape_type\"] == \"circle\":\n",
    "            xy = np.asarray(sh[\"points\"])\n",
    "            ave = np.mean(xy, axis=0)\n",
    "\n",
    "            cx = min(int(round(ave[1])), imgShape[0] - size // 2)\n",
    "            cx = max(cx, size // 2)\n",
    "            cy = min(int(round(ave[0])), imgShape[1] - size // 2)\n",
    "            cy = max(cy, size // 2)\n",
    "\n",
    "            minr = cx - size // 2; maxr = cx + size // 2\n",
    "            minc = cy - size // 2; maxc = cy + size // 2\n",
    "\n",
    "            crop = img[minr:maxr, minc:maxc]\n",
    "\n",
    "            # trim offset and scale from filename\n",
    "            if FILENAME_TRIM:\n",
    "                a, scale, offset, b = imgfn.split('|')\n",
    "                savefn = f'{a}'.replace(\" \", \"\")\n",
    "            else:\n",
    "                savefn = imgfn\n",
    "\n",
    "            savefn = f'{savefn}-{n}{suffix}'\n",
    "            # savefn = f'{dest_path}/{savefn}-{n}{suffix}'\n",
    "\n",
    "            # print('saving', savefn)\n",
    "            if not debug:\n",
    "                if suffix == '.jpg':\n",
    "                    PIL.Image.fromarray(crop.astype(np.uint8)).save(dest_path/savefn, quality=90)\n",
    "                elif suffix == '.png':\n",
    "                    lbl_pil = PIL.Image.fromarray(crop.astype(np.uint8), mode='P')\n",
    "                    lbl_pil.putpalette(colormap)\n",
    "                    lbl_pil.save(dest_path/savefn)\n",
    "            else:\n",
    "                print('x', end='')\n",
    "\n",
    "\n",
    "            item = {'Name': savefn, 'Label': sh[\"label\"], 'Op': op}\n",
    "            croplist.append(item)\n",
    "    # print(f'Saved {n} files in {dest_path}')\n",
    "    return croplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def crop_img_dir(file_data:str, json_path:str, src_path:str, dest_path:str, number_files='all', DEBUG=False):\n",
    "    \"\"\"\n",
    "    Crop directory of image files based on json centers and store in dest directory\n",
    "    - `file_data:`    file_data.csv  \n",
    "    - `src_path:`     path where json files and image files to be cropped are  \n",
    "    - `dest_path:`    Destination path to store cropped files  \n",
    "    - `number_files:` Number of json files to process, leave empty for all files in directory  \n",
    "    - `size:`         pixel size of crop  \n",
    "    - `return:`       total number of cropped images`  \n",
    "    \"\"\"\n",
    "    if DEBUG: print (f'Debug = {DEBUG} so not saving files')\n",
    "    # assert subdir in ['Train', 'Val', 'Test', None], \"subdir must one of 'Train', 'Val', 'Test' or None\"\n",
    "\n",
    "    src_df = pandas.read_csv(file_data, index_col=0)\n",
    "    if number_files == 'all':\n",
    "        __number_files = src_df.shape[0]\n",
    "    elif isinstance(number_files, int) :\n",
    "        __number_files = number_files\n",
    "    else:\n",
    "        __number_files = 0\n",
    "\n",
    "    json_path = Path(json_path)\n",
    "    src_path = Path(src_path)\n",
    "    dest_path = Path(dest_path)\n",
    "\n",
    "    (dest_path/'Train').mkdir(parents=True, exist_ok=True)\n",
    "    (dest_path/'Test').mkdir(parents=True, exist_ok=True)\n",
    "    (dest_path/'Label').mkdir(parents=True, exist_ok=True)\n",
    "    (dest_path/'Error').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f'{__number_files} files to process in {src_path}' )\n",
    "\n",
    "    misslist = []\n",
    "    croplist = []\n",
    "    vallist = []\n",
    "    for i in range(__number_files):\n",
    "        imgfn = src_df.loc[i,'Name']\n",
    "        f_stem = imgfn.split('.')[0]\n",
    "        labfn = f'{f_stem}.png'\n",
    "        jsonfn = f'{f_stem}.json'\n",
    "        if (src_path/imgfn).exists():\n",
    "            fn = imgfn\n",
    "            file_type = \"IMAGE\"\n",
    "        elif (src_path/labfn).exists():\n",
    "            fn = labfn\n",
    "            file_type = \"LABEL\"\n",
    "        else:\n",
    "            fn = None\n",
    "        if (json_path/jsonfn).exists() and fn is not None:\n",
    "            op = src_df.loc[i, 'Op']\n",
    "            if file_type == \"LABEL\":\n",
    "                cropdir = dest_path / 'Label'\n",
    "            elif op == 'Valid' or src_df.loc[i, 'Op'] == 'Train':\n",
    "                cropdir = dest_path / 'Train'\n",
    "            elif op == 'Test':\n",
    "                cropdir = dest_path / 'Test'\n",
    "            else:\n",
    "                print(f'File: {imgfn} has no Op label or is not a label file')\n",
    "                cropdir = dest_path / 'Error'\n",
    "\n",
    "            # if op == 'Valid' and file_type == \"IMAGE\":\n",
    "            #     vallist += lst\n",
    "\n",
    "            lst = __crop_image(json_path/jsonfn, src_path/fn, cropdir, op=op, size=200, debug=DEBUG)\n",
    "\n",
    "            croplist += lst\n",
    "\n",
    "\n",
    "            progress_bar(i + 1, 50)\n",
    "        else:\n",
    "            misslist.append(f_stem)\n",
    "\n",
    "    print('')\n",
    "    print(f'Missed {len(misslist)} and  Cropped {len(croplist)} files in {dest_path}')\n",
    "\n",
    "    # savefn = dest_path / 'valid.txt'\n",
    "    # print(f\"Saving {len(vallist)} valid file names in {savefn}\")\n",
    "    # if len(vallist) > 0:\n",
    "    #     with open(savefn, \"w\") as a:\n",
    "    #         for item in vallist:\n",
    "    #             fn = item['Name']\n",
    "    #             if Path(fn).suffix == '.jpg' :\n",
    "    #                 a.write(fn + os.linesep)\n",
    "\n",
    "    return misslist, croplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def move_files_to_dir( movefiles, srcpath, destpath, operation='move', extns=['.jpg','.json','.png']):\n",
    "    \"\"\"\n",
    "    Move random shuffle of the source directory to the Train, Val and Test directories\n",
    "\n",
    "    :param movefiles: list of files to move\n",
    "    :param srcpath: path where to src train files\n",
    "    :param destpath: path where to put test files\n",
    "    :param extns: list of extensions to try\n",
    "    :return: cnt of files_moved, files_missed\n",
    "    \"\"\"\n",
    "\n",
    "    files_moved = [0]*3\n",
    "    files_missed = [0]*3\n",
    "    Path(destpath).mkdir(parents=True, exist_ok=True)\n",
    "    for fn in movefiles:\n",
    "        fn = Path(f'{srcpath}/{fn}')\n",
    "        for i, ext in enumerate(extns):\n",
    "            if fn.with_suffix(ext).exists():\n",
    "                if operation == 'copy':\n",
    "                    shutil.copy(str(fn.with_suffix(ext)), str(destpath))\n",
    "                elif operation == 'move':\n",
    "                    shutil.move(str(fn.with_suffix(ext)), str(destpath))\n",
    "                files_moved[i] += 1\n",
    "            else:\n",
    "                files_missed[i] += 1\n",
    "\n",
    "    print( \"Files Moved\", files_moved)\n",
    "    print( \"Files Missed\", files_missed)\n",
    "\n",
    "        # print(f'Moved {len(jpg_cnt)} jpg files, {json_cnt} json files and  {png_cnt} png files to {movefiles}')\n",
    "\n",
    "    return files_moved, files_missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def old_move_files_to_dir( movefiles, srcpath, destpath, operation='move', extns=['.jpg','.json','.png']):\n",
    "    \"\"\"\n",
    "    Move random shuffle of the source directory to the Train, Val and Test directories\n",
    "\n",
    "    :param movefiles: list of files to move\n",
    "    :param srcpath: path where to src train files\n",
    "    :param destpath: path where to put test files\n",
    "    :param extns: list of extensions to try\n",
    "    :return: cnt of files_moved, files_missed\n",
    "    \"\"\"\n",
    "\n",
    "    files_moved = [0]*3\n",
    "    files_missed = [0]*3\n",
    "    Path(destpath).mkdir(parents=True, exist_ok=True)\n",
    "    for fn in movefiles:\n",
    "        fn = Path(f'{srcpath}/{fn}')\n",
    "        for i, ext in enumerate(extns):\n",
    "            if fn.with_suffix(ext).exists():\n",
    "                if operation == 'copy':\n",
    "                    shutil.copy(str(fn.with_suffix(ext)), str(destpath))\n",
    "                elif operation == 'move':\n",
    "                    shutil.move(str(fn.with_suffix(ext)), str(destpath))\n",
    "                files_moved[i] += 1\n",
    "            else:\n",
    "                files_missed[i] += 1\n",
    "\n",
    "    print( \"Files Moved\", files_moved)\n",
    "    print( \"Files Missed\", files_missed)\n",
    "\n",
    "        # print(f'Moved {len(jpg_cnt)} jpg files, {json_cnt} json files and  {png_cnt} png files to {movefiles}')\n",
    "\n",
    "    return files_moved, files_missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def create_labels_dir(json_path, dest_path, number_files='all'):\n",
    "    \"\"\"\n",
    "     Create label png images based on CSV files and store in dest directory\n",
    "\n",
    "    :param json_path: Source path where json files are\n",
    "    :param dest_path: Destination path to store created png label files\n",
    "    :param number_files: Number of json files to process, leave empty for all files in directory\n",
    "    :return: nil\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    lab_path = Path(dest_path)\n",
    "    lab_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fnames_json = sorted(get_files(json_path, extensions=['.json']))\n",
    "    if isinstance(number_files, int):\n",
    "        fnames_json = fnames_json[:number_files]\n",
    "    colormap = colormap_segmentation_labels()\n",
    "    print(\"Number of json files to process\", len(fnames_json))\n",
    "    \n",
    "    if 1:\n",
    "        for i,fn in enumerate(fnames_json):\n",
    "            create_one_label(fn, i, json_path, lab_path, colormap)\n",
    "            progress_bar(i + 1, 50)\n",
    "    else:\n",
    "        parallel(partial(create_one_label, json_path=json_path, lab_path=lab_path, colormap=colormap), fnames_json, leave=True)\n",
    "    print(\"Number of labels files created\", len(fnames_json))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}