{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference Utilities\n",
    "> Functions that are used to markup up files with a learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "# default_exp inference_utils\n",
    "from nbdev.showdoc import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from cellsegment.core import *\n",
    "from fastai.vision import *\n",
    "from fastai.utils.mem import *\n",
    "\n",
    "import cv2\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "# from skimage import filters\n",
    "# from skimage.morphology import erosion, dilation, opening, closing, disk\n",
    "# from scipy.spatial import distance\n",
    "# import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "## General Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def run_inferences(learn:Learner, fnames:list, start:int=0, number_files=20) -> list:\n",
    "    \"\"\"\n",
    "    run inferences over a list of `fnames` using `learner`\n",
    "    - return a list of predictions\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    if number_files == 'all':\n",
    "        __number_files = len(fnames)\n",
    "    elif isinstance(number_files, int) :\n",
    "        __number_files = number_files\n",
    "    else:\n",
    "        __number_files = 0\n",
    "    for i in range(start, start+__number_files):\n",
    "        if i >= len(fnames): break\n",
    "        img = open_image(fnames[i])\n",
    "        y, pred, raw_pred = learn.predict(img)\n",
    "        preds.append({\"filename\": fnames[i].name, \"y\": y,\"pred\": pred,\"raw_pred\": raw_pred})\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def plot_inferences(preds:List, df:DataFrame, src_path:Path=Path(''), label=None, start:int=0, rows:int = 4, cols:int=5) -> None:\n",
    "    \"\"\"\n",
    "    Plot test images with auto markup labels\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*3, rows*3))\n",
    "    ax_lst = []\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i+start >= len(preds): break\n",
    "        fpath = src_path/preds[i+start][\"filename\"]\n",
    "        img = open_image(fpath)\n",
    "        width, height = img.size\n",
    "        show_image(img, ax=ax)\n",
    "        show_image(preds[i+start][\"y\"], ax=ax,  cmap='tab20', alpha=0.5)\n",
    "        fn = Path(fpath).name\n",
    "        # B,L,R,O = df.loc[fn, 'Background'], df.loc[fn, 'Fluke Liver'], df.loc[fn, 'Fluke Rumen'],df.loc[fn, 'Other']\n",
    "        draw_text(ax, (0, 0), f'{fpath.name}', sz=14, color='red')\n",
    "        pstr = ''\n",
    "        if label in df.columns:\n",
    "            pstr = df.loc[df['Name'] == fn, label].values[0]\n",
    "            draw_text(ax, (0, height-20), pstr, sz=14, color='red')\n",
    "\n",
    "        true_label = df.loc[df['Name'] == fn, 'Label'].values[0]\n",
    "        ax.set_title(f\"File {fpath.name} \\n GT={true_label} P={pstr}\")\n",
    "        ax_lst.append(ax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# def \n",
    "# def create_probs_df(fnames: List, ) -> DataFrame:\n",
    "#     \"\"\"\n",
    "#     create a data frame of prob from a `fname` list\n",
    "#      - param fnames: \n",
    "#      - return: `DataFrame`\n",
    "#     \"\"\"\n",
    "#     list_filedata = [None] * len(fnames)\n",
    "#     for i, fn in enumerate(fnames):\n",
    "#         # img = PIL.Image.open(fn)\n",
    "#         # img_w, img_h = img.size\n",
    "#         list_filedata[i] = {'Name': fn.name, 'Background': '', 'Fluke Liver': '', 'Fluke Rumen': '', 'Other': '', 'Pstr': ''}\n",
    "# \n",
    "#     df = pd.DataFrame(list_filedata)\n",
    "#     df = df[['Name', 'Background', 'Fluke Liver', 'Fluke Rumen', 'Other', 'Pstr']]\n",
    "#     df.set_index(\"Name\", inplace=True)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_region_props(raw_pred:tensor, layer:int, min_conf:float=0.2, min_area:int = 100) -> list:\n",
    "    ' return all the region properties of a prediction layer filtered by min confidence and min area '\n",
    "    arr = raw_pred[layer, :, :].numpy()\n",
    "    if layer == 0:\n",
    "        label_arr = label(arr < 1 - min_conf)\n",
    "    else:\n",
    "        label_arr = label(arr > min_conf)\n",
    "\n",
    "    region_props = []\n",
    "    for region in regionprops(label_arr, arr, cache=True):\n",
    "        if region.area > min_area:\n",
    "            cx = int(region.centroid[1])\n",
    "            cy = int(region.centroid[0])\n",
    "            region_props.append({\n",
    "                \"class_layer\": layer,\n",
    "                \"centroid\": region.centroid,\n",
    "                \"mean_intensity\": region.mean_intensity,\n",
    "                \"area\": region.area,\n",
    "                \"coords\": region.coords,\n",
    "            })\n",
    "    return region_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def calc_probs(raw_pred:tensor)->list:\n",
    "    \"\"\"\n",
    "    Calculate the probabilities from a raw prediction  `raw_pred`\n",
    "    by finding the average value of all the pixels within a region\n",
    "    This assumes that there is only one cell in the image\n",
    "    - `raw_pred`: the raw predictions from the learner\n",
    "    - `return`:  list of probabilities\n",
    "    \"\"\"\n",
    "    def __get_bool_mask(o):\n",
    "        min_conf = 0.5\n",
    "        arr = o[0, :, :].numpy()\n",
    "        bgnd = get_region_props(o, 0, min_conf)\n",
    "        if len(bgnd) > 0:\n",
    "            mask = np.zeros((arr.shape), dtype=bool)\n",
    "            AAcoords = bgnd[0][\"coords\"]  # TODO uses first region only\n",
    "            mask[tuple(AAcoords.T.tolist())] = True\n",
    "        else:\n",
    "            mask = None\n",
    "        return mask\n",
    "\n",
    "    mask = __get_bool_mask(raw_pred)\n",
    "    if mask is not None:\n",
    "        p = [None] * raw_pred.shape[0]\n",
    "        for i in range(raw_pred.shape[0]):\n",
    "            p[i] = raw_pred[i, :, :].numpy()[mask].mean().round(2)\n",
    "    else:\n",
    "        p = []\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def preds_to_df(preds:List, col_headings: List,  df:DataFrame):\n",
    "    \"\"\"\n",
    "    add the predictions to the dataframe indexed by fname\n",
    "    - preds: prediction list\n",
    "    - col_headings: column headings\n",
    "    - df: dataframe\n",
    "    - return:\n",
    "    \"\"\"\n",
    "    for c in col_headings:\n",
    "        if not c in df.columns:\n",
    "            df[c] = ''\n",
    "    assert len(col_headings) == len(preds[0]), f' len(col_headings) != len(preds[0])'\n",
    "\n",
    "    for i, pred in enumerate(preds):\n",
    "        fn = Path(pred[\"filename\"]).name\n",
    "        probs = calc_probs(pred[\"raw_pred\"])\n",
    "        if len(probs) > 0:\n",
    "            pstr = f\"B:{probs[0]:3.2f} L:{probs[1]:3.2f} R:{probs[2]:3.2f}\"\n",
    "            df.loc[df['Name'] == fn, col_headings] = probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on whole images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_prediction_blobs(img, CONF=0.5, min_area=500,offset=0):\n",
    "    ' plot the prediction blobs on an image '\n",
    "    # region props seems to have region.max_intensity errors if no data not np.int\n",
    "    SCALE = 100\n",
    "    CONF *= SCALE\n",
    "\n",
    "    img = (img * (SCALE / img.max())).astype(np.int)\n",
    "    img[img[:, :, 0] < CONF, 0] = 0\n",
    "    img[img[:, :, 1] < CONF, 1] = 0\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    fill = (255, 0, 0)\n",
    "    label_image0 = label(img[:, :, 0] > CONF)\n",
    "    label_image1 = label(img[:, :, 1] > CONF)\n",
    "\n",
    "    print ('Label 0')\n",
    "    img = np.array(img)  # helped with a cv error?\n",
    "    for region in regionprops(label_image0, img[:, :, 0], cache=True):\n",
    "        if region.area > min_area:\n",
    "            cx = int(region.centroid[1]) + offset\n",
    "            cy = int(region.centroid[0])\n",
    "            predictions.append({\"label\": 'Strongyle', \"particleType\": 1, \"point\": [cx, cy],\n",
    "                                \"probability\": int(region.max_intensity.round(2))})\n",
    "            print(' 0:', [cx,cy], 'area:',  region.area,\n",
    "                      'max',  region.max_intensity.round(2),\n",
    "                      'mean', region.mean_intensity.round(2))\n",
    "    print ('Label 1')\n",
    "    fill = (0, 255, 0)\n",
    "    img = np.array(img)  # helped with a cv error?\n",
    "    for region in regionprops(label_image1, img[:, :, 1]):\n",
    "        if region.area > min_area:\n",
    "            cx = int(region.centroid[1]) + offset\n",
    "            cy = int(region.centroid[0])\n",
    "            predictions.append({\"label\": 'Nematodirus', \"particleType\": 2, \"point\": [cx, cy],\n",
    "                                \"probability\": int(region.max_intensity.round(2))})\n",
    "            print(' 0:', [cx, cy], 'area:', region.area,\n",
    "                  'max', region.max_intensity.round(2),\n",
    "                  'mean', region.mean_intensity.round(2))\n",
    "\n",
    "    return predictions, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def draw_labels_on_image(img, json, radius=40, offset=0):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for s, sh in enumerate(json['shapes']):\n",
    "        if sh[\"label\"][:3] == \"Str\":\n",
    "            fill = (1, 0, 0)\n",
    "        elif sh[\"label\"][:3] == \"Nem\":\n",
    "            fill = (0, 1, 0)\n",
    "        else:\n",
    "            print('[Error]: unknown label')\n",
    "\n",
    "        draw = 'None'\n",
    "        if sh['shape_type'] == 'circle':\n",
    "            draw = 'circle'\n",
    "            probability = str(sh['probability']) if 'probability' in sh else ''\n",
    "        elif sh['shape_type'] == 'rectangle':\n",
    "            draw = 'rectangle'\n",
    "            probability = str(sh['probability']) if 'probability' in sh else ''\n",
    "        else:\n",
    "            print(\"Unknown shape_type\", sh['shape_type'])\n",
    "\n",
    "        xy = np.asarray(sh[\"points\"])\n",
    "        ave = np.mean(xy, axis=0)\n",
    "\n",
    "        cx = int(ave[0]) - offset\n",
    "        cy = int(ave[1])\n",
    "\n",
    "        if draw == 'circle':\n",
    "            cv2.circle(img, (cx, cy), radius, fill, 2)\n",
    "            cv2.circle(img, (cx, cy), radius, fill, 2)\n",
    "\n",
    "        elif draw == 'rectangle':\n",
    "            cv2.rectangle(img, (cx - radius, cy - radius), (cx + radius, cy + radius), fill, 2)\n",
    "            cv2.putText(img, probability, (int(cx - radius), cy - radius - 5), font, 0.8, fill, 2, cv2.LINE_AA)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# def unetCountEggsInWell(learn, img):\n",
    "#     PAD = 50\n",
    "#     TM, TN = 2, 2\n",
    "#     min_area = 100\n",
    "#     anno_radius = 20\n",
    "#\n",
    "#     img = resize(img, (2464 // 2, 3450 // 2))\n",
    "#\n",
    "#     offset, img = crop2well(img, width=2464 // 2, plot=False)\n",
    "#     img_f = img.transpose(2, 0, 1).astype(np.float32)\n",
    "#     imglist = dice_image(torch.from_numpy(img_f), TM=TM, TN=TN, pad=PAD)\n",
    "#     print(\"Number of tiles = \", len(imglist))\n",
    "#\n",
    "#     pred_list = []\n",
    "#     for n, im in enumerate(imglist):\n",
    "#         print(f\"Predictig Tile {n}\")\n",
    "#         pc, pi, o = learn.predict(im)\n",
    "#         pred_list.append(o)\n",
    "#\n",
    "#     pred_img = tile_image(pred_list, TM=TM, TN=TN, pad=PAD)\n",
    "#\n",
    "#     pred_img[0, :, :] = pred_img[1, :, :]\n",
    "#     pred_img[1, :, :] = pred_img[2, :, :]\n",
    "#     pred_img[2, :, :] = 0\n",
    "#\n",
    "#     pred_img[pred_img<0.3] = 0\n",
    "#     pred_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def add_cols_to_df(df: DataFrame, col_list: List) -> DataFrame:\n",
    "    \"\"\"\n",
    "    To dataframe `df` add columns in `col_list`\n",
    "    - df: dataframe to add columns to\n",
    "    - col_list: list of columns to add\n",
    "    - return: the df\n",
    "    \"\"\"\n",
    "    add_col = [''] * df.shape[0]\n",
    "    for l in col_list:\n",
    "        df[l] = add_col\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Drawing functions\n",
    "> Draw text and graphics on an matplotlib image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def bb_hw(a): return np.array([a[1], a[0], a[3] - a[1], a[2] - a[0]])\n",
    "\n",
    "def draw_outline(o, lw):\n",
    "    o.set_path_effects([patheffects.Stroke(\n",
    "        linewidth=lw, foreground='black'), patheffects.Normal()])\n",
    "\n",
    "def draw_rect(ax, b):\n",
    "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor='white', lw=2))\n",
    "    draw_outline(patch, 4)\n",
    "\n",
    "def draw_text(ax, xy, txt, sz=12, color='white', valign='top'):\n",
    "    text = ax.text(*xy, txt,\n",
    "                   verticalalignment=valign, color=color, fontsize=sz)  # , weight='bold')\n",
    "    draw_outline(text, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}