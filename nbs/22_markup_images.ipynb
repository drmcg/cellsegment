{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Example - markup_images  \n",
    "> **Model trained On the AM0.1-FLUKE dataset**  \n",
    "Load the model and run inferences on the test dataset   \n",
    "**[Run this file online in Colab](https://colab.research.google.com/github/johnnewto/cellsegment/blob/master/nbs/23_example_evaluation_inference.ipynb)**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#hide\n",
    "# default_exp temp_markup_images\n",
    "from cellsegment.core import *\n",
    "from nbdev.showdoc import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "def in_colab():\n",
    "    \"Check if the code is running in Google Colaboratory\"\n",
    "    try:\n",
    "        from google import colab\n",
    "        return True\n",
    "    except: return False\n",
    "IN_COLAB = in_colab()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#hide\n",
    "if IN_COLAB:\n",
    "    import os\n",
    "    print('Cloning the cellsegment library')\n",
    "    os.system('mkdir -p /root/.torch/models')\n",
    "    os.system('mkdir -p /root/.fastai/data')\n",
    "    os.system('ln -s /root/.torch/models /content')\n",
    "    os.system('ln -s /root/.fastai/data /content')\n",
    "    os.system('rm -rf /content/sample_data/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from cellsegment.core import *\n",
    "from cellsegment.inference_utils import *\n",
    "from cellsegment.set_directories import *\n",
    "import pandas\n",
    "from fastai.vision import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define directories"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "None\n  basepath        :  ../testdata_2        \n  crop            :  ../testdata_2/Crop-200 \n  cropLabel       :  ../testdata_2/Crop-200/Label \n  cropTest        :  ../testdata_2/Crop-200/Test \n  cropTrain       :  ../testdata_2/Crop-200/Train \n  cropValidTxtFile:  ../testdata_2/Crop-200/valid.txt \n  label           :  ../testdata_2/Fullsize/Label \n  model           :  /home/john/github/data/FEC/03-M100-Fluke-2019-11/models \n  originImages    :  ../testdata_2/Original \n  sizeCsvFile     :  ../testdata_2/file_size.csv \n  test            :  ../testdata_2/Fullsize/Test \n  train           :  ../testdata_2/Fullsize/Train \n  validTxtFile    :  ../testdata_2/Fullsize/valid.txt \n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "local_datapath = '../testdata_2'\n",
    "# local_datapath = '../../data/FEC/03-M100-Fluke-2019-11/'\n",
    "\n",
    "dirs = Dirs('data') if IN_COLAB else Dirs(local_datapath)\n",
    "dirs.model = dirs.model if IN_COLAB else '/home/john/github/data/FEC/03-M100-Fluke-2019-11/models'\n",
    "\n",
    "print(dirs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the Training Images \n",
    "(if in colab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "%%bash\n",
    "[[ ! -e /tools/google-cloud-sdk ]] &&  exit # if in colab\n",
    "\n",
    "    export fileid=1SEW0Kf1CI4e4-up4TGsDqwDwVk_QZEUf\n",
    "    export filename=Fluke-Train-2019-12-01.zip\n",
    "\n",
    "    ## CURL ##\n",
    "    curl -L -c cookies.txt 'https://docs.google.com/uc?export=download&id='$fileid \\\n",
    "         | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1/p' > confirm.txt\n",
    "    curl -L -b cookies.txt -o $filename \\\n",
    "         'https://docs.google.com/uc?export=download&id='$fileid'&confirm='$(<confirm.txt)\n",
    "    rm -f confirm.txt cookies.txt\n",
    "    \n",
    "    unzip -u -q $filename -d data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load exported Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "%%bash\n",
    "[[ ! -e /tools/google-cloud-sdk ]] &&  exit # if in colab\n",
    "switch=true\n",
    "if $switch; then  \n",
    "    export fileid=11cZWhg23QDag_3b7jcd02U8Pzq3W6U5Y\n",
    "    export filename=export-fluke-2019-12-01.pkl\n",
    "\n",
    "    ## CURL ##\n",
    "    curl -L -c cookies.txt 'https://docs.google.com/uc?export=download&id='$fileid \\\n",
    "         | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1/p' > confirm.txt\n",
    "    curl -L -b cookies.txt -o $filename \\\n",
    "         'https://docs.google.com/uc?export=download&id='$fileid'&confirm='$(<confirm.txt)\n",
    "    rm -f confirm.txt cookies.txt\n",
    "fi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run model inference on all of the test tiles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Number of test tiles 13\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "path = Path(dirs.crop)\n",
    "fnames =  get_image_files(path/'Test')\n",
    "\n",
    "print (f'Number of test tiles {len(fnames)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Learner from exported model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Learner loaded\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# defaults.device = 'cpu'\n",
    "defaults.device = 'cuda'\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    def acc_metric1(input, target):\n",
    "        target = target.squeeze(1)\n",
    "        return (input.argmax(dim=1)==target).float().mean()\n",
    "\n",
    "    def acc_metric2(input, target):\n",
    "        target = target.squeeze(1)\n",
    "        return (input.argmax(dim=1)[target>0]==target[target>0]).float().mean()\n",
    "\n",
    "    fn_model = f'{dirs.model}/export-fluke-2019-12-01.pkl'\n",
    "    learn = load_learner('', fn_model)\n",
    "\n",
    "    learn.model.float()\n",
    "    # summary(learn.model, (3, 32, 32))\n",
    "    print(\"Learner loaded\")\n",
    "else:\n",
    "    print(\"Learner not loaded as torch.cuda.is_available() = \", torch.cuda.is_available())\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## utilities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def padImage_t(img, pad=100):\n",
    "    if pad and pad > 0:\n",
    "        return F.pad(input=img.px, pad=(pad, pad, pad, pad), mode='constant', value=0)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def cut_tiles_t(img, TM=4, TN=4, pad=100):\n",
    "    M, N = (img.shape[1]-pad*2)//TM, (img.shape[2]-pad*2)//TN \n",
    "    OM, ON = pad + M//2, pad + N//2   \n",
    "    return [Image(img[:,x-OM:x+OM,y-ON:y+ON]) for x in range(pad+M//2,img.shape[1],M) for y in range(pad+N//2,img.shape[2],N)]\n",
    "\n",
    "def lay_tiles_t(tiles, TM=4, TN=4, pad=100):\n",
    "    (_,M,N) = tiles[0].size()\n",
    "    OM, ON = pad + M//2, pad + N//2  \n",
    "    for n, tile in enumerate(tiles):\n",
    "        tiles[n] = tile[:,pad:-(pad+1),pad:-(pad+1)]\n",
    "    \n",
    "    hstack = [torch.cat(tiles[y:y+TN],dim=2) for y in range(0,TN*TM,TN)]  \n",
    "    return torch.cat(hstack,dim=1)\n",
    "\n",
    "def run_prediction(learn, fn, classes=None, filesavedir=None, tile=False, pad=100):\n",
    "    \"\"\"\n",
    "    run predictions and return dictionary of raw predictions\n",
    "    :param learn: \n",
    "    :param fn: \n",
    "    :param classes: \n",
    "    :param tile: \n",
    "    :param pad: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    img = open_image(fn)\n",
    "    if tile:\n",
    "        pad = 100\n",
    "        TM, TN =2, 2\n",
    "        img = padImage_t(img, pad=pad)\n",
    "        tiles = cut_tiles_t(img, TM=TM, TN=TN, pad=pad)\n",
    "        outputs = [learn.predict(im)[2] for im in tiles]\n",
    "        raw_pred = lay_tiles_t(outputs, TM=TM, TN=TN, pad=pad)\n",
    "    else:\n",
    "        if img.shape[2]%2 == 1:   # make odd dimension make even for unet\n",
    "           img.px = img.px[:,:,1:] \n",
    "        _,_,raw_pred = learn.predict(img)\n",
    "      \n",
    "    preds = {c:raw_pred[i,:,:] for i,c in enumerate(classes)}\n",
    "    if filesavedir:\n",
    "        for cls,raw_pred in preds.items():\n",
    "            print(cls, raw_pred.shape)\n",
    "            # lbl_pil = PIL.Image.fromarray(to_np(raw_pred*255).astype(np.uint8))\n",
    "            # lbl_pil = lbl_pil.convert('P', palette=PIL.Image.ADAPTIVE, colors=256)\n",
    "            # lbl_pil.save(f'{filesavedir}/{fn.stem}-{cls}.png')\n",
    "            save_png_p(to_np(raw_pred), f'{filesavedir}/{fn.stem}-{cls}.png')\n",
    "\n",
    "    return preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Number images to process 3\n",
      "Background torch.Size([800, 816])\nFluke_Liver torch.Size([800, 816])\nFluke_Rumen torch.Size([800, 816])\nOther torch.Size([800, 816])\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "torch.Size([800, 816])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 36
    }
   ],
   "source": [
    "img_path = Path(dirs.train)\n",
    "mrk_path = Path('../testdata_2/Fullsize/markup')  \n",
    "mrk_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fnames = sorted(get_image_files(img_path))\n",
    "classes = ['Background', 'Fluke_Liver', 'Fluke_Rumen', 'Other']\n",
    "\n",
    "# fnames = fnames[600:]\n",
    "fnames = fnames[:3]\n",
    "print(f\"Number images to process {len(fnames)}\")\n",
    "preds = run_prediction(learn, fnames[1], classes=classes, tile=False, filesavedir=mrk_path)\n",
    "preds['Background'].shape\n",
    "# for fn in fnames:\n",
    "#     print(fn)\n",
    "#     pred_img = unet_predict_eggs(fn)\n",
    "#     PIL.Image.fromarray((pred_img*255).astype(np.uint8)).save(f'{mrk_path}/{fn.stem}.png')  \n",
    "# show_img(pred_img)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "## Class Analyse Predictions\n",
    "# import pdb; pdb.set_trace()\n",
    "import cv2\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import filters\n",
    "from skimage.morphology import erosion, dilation, opening, closing, disk\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "class AnalysePredictions(object):\n",
    "    \"\"\"Methods for preparing and the inference of Well images\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"What to do here\"\"\"\n",
    "        self.set_paths();\n",
    "\n",
    "    def set_paths(self, base_path=None, img_path=None, mrk_path=None):\n",
    "        if base_path is None:\n",
    "            base_path = Path().absolute()\n",
    "        if img_path is not None:\n",
    "            self.img_path = base_path/Path(img_path) \n",
    "            self.mrk_path = base_path/Path(mrk_path)\n",
    "        else:\n",
    "            self.img_path = Path('data/images/')\n",
    "            self.mrk_path = Path('data/markup/')\n",
    "        \n",
    "    # NP coder for Tile  into  MxN sections to reduce memory footprint\n",
    "    def padImage_np(self, img, padding=100):\n",
    "      if padding and padding > 0:\n",
    "        return np.stack([np.pad(img[:,:,c], padding, mode='constant', constant_values=0) for c in range(3)], axis=2)\n",
    "      else:\n",
    "        return img\n",
    "\n",
    "    def cut_tiles_np(img, TM=4, TN=4, pad=100):\n",
    "      M, N = (img.shape[0]-pad*2)//TM, (img.shape[1]-pad*2)//TN \n",
    "      OM, ON = pad + M//2, pad + N//2\n",
    "      return [img[x-OM:x+OM,y-ON:y+ON,:] for x in range(pad+M//2,img.shape[0],M) for y in range(pad+N//2,img.shape[1],N)]\n",
    "\n",
    "    def lay_tiles_np(self, tiles, TM=4, TN=4, pad=100):\n",
    "      OM, ON = pad + TM//2, pad + TN//2\n",
    "      for n, tile in enumerate(tiles):\n",
    "        tiles[n] = tile[pad:-pad,pad:-pad,:]\n",
    "\n",
    "      hstack = [np.concatenate(tiles[y:y+TN],axis=1) for y in range(0,TN*TM,TN)]  \n",
    "      return np.concatenate(hstack,axis=0)\n",
    "\n",
    "    def test_tile_np(self):\n",
    "        img = to_np(open_image('data/subset/220972 - 1.jpg').resize(800).px).transpose(1,2,0)\n",
    "        img = self.padImage_np(img)\n",
    "        tiles = self.cut_tiles_np(img)\n",
    "        vstack = self.lay_tiles_np(tiles, TM=4, TN=4, pad=100)\n",
    "        show_img(vstack, figsize = (10,10))\n",
    "\n",
    "    ## Tensor coder for Tile  into  MxN sections to reduce memory footprint\n",
    "\n",
    "    def padImage_t(self, img, pad=100):\n",
    "      if pad and pad > 0:\n",
    "        return F.pad(input=img.px, pad=(pad, pad, pad, pad), mode='constant', value=0)\n",
    "      else:\n",
    "        return img\n",
    "\n",
    "    def cut_tiles_t(self, img, TM=4, TN=4, pad=100):\n",
    "      M, N = (img.shape[1]-pad*2)//TM, (img.shape[2]-pad*2)//TN \n",
    "      OM, ON = pad + M//2, pad + N//2  \n",
    "      return [Image(img[:,x-OM:x+OM,y-ON:y+ON]) for x in range(pad+M//2,img.shape[1],M) for y in range(pad+N//2,img.shape[2],N)]\n",
    "\n",
    "    def lay_tiles_t(self, tiles, TM=4, TN=4, pad=100):\n",
    "      (_,M,N) = tiles[0].size()\n",
    "      OM, ON = pad + M//2, pad + N//2  \n",
    "      for n, tile in enumerate(tiles):\n",
    "        tiles[n] = tile[:,pad:-(pad+1),pad:-(pad+1)]\n",
    "\n",
    "      hstack = [torch.cat(tiles[y:y+TN],dim=2) for y in range(0,TN*TM,TN)]  \n",
    "      return torch.cat(hstack,dim=1)\n",
    "\n",
    "    def test_tile_t(self):\n",
    "        img = open_image('data/subset/220972 - 1.jpg')\n",
    "        # img = to_np(open_image('data/subset/220972 - 1.jpg').resize(800).px).transpose(1,2,0)\n",
    "        img = padImage_t(img)\n",
    "        tiles = cut_tiles_t(img)\n",
    "\n",
    "        for n, tile in enumerate(tiles):\n",
    "            tiles[n] = tile.px\n",
    "            print(tile.px.shape)\n",
    "\n",
    "        vstack = lay_tiles_t(tiles)\n",
    "        Image(vstack).show(figsize = (10,10))\n",
    "\n",
    "    ## Drawing annotation labels on an image\n",
    "    def draw_labels_cv(self, img, json, radius=40):\n",
    "      font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "      for s, sh in enumerate(json['shapes']):\n",
    "        if sh[\"label\"][:3] == \"Str\":\n",
    "          fill = (255,0,0)\n",
    "        elif sh[\"label\"][:3] == \"Nem\":\n",
    "          fill = (0,255,0)\n",
    "        else:\n",
    "          print('[Error]: unknown label')\n",
    "\n",
    "        draw = 'None'  \n",
    "        if sh['shape_type'] == 'circle':\n",
    "          draw = 'circle'\n",
    "          probability = str(sh['probability']) if 'probability' in sh else ''\n",
    "        elif sh['shape_type'] == 'rectangle':\n",
    "          draw = 'rectangle'\n",
    "        else:\n",
    "          print(\"Unknown shape_type\", sh['shape_type'])\n",
    "\n",
    "\n",
    "        xy = np.asarray(sh[\"points\"])\n",
    "        ave = np.mean(xy,axis=0)\n",
    "\n",
    "        cx = int(ave[0])\n",
    "        cy = int(ave[1])\n",
    "\n",
    "        if draw == 'circle':\n",
    "          cv2.circle(img, (cx, cy), radius, fill, 2)\n",
    "          cv2.circle(img, (cx, cy), radius, fill, 2)\n",
    "          cv2.putText(img,probability,(int(cx-radius), cy-radius), font, 1, fill, 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        elif draw == 'rectangle':\n",
    "          cv2.rectangle(img, (cx - radius, cy - radius), (cx + radius, cy + radius), fill, 2)\n",
    "\n",
    "      return img\n",
    "    def test_draw_labels_cv(self):\n",
    "        img_path = Path('data/subset/')\n",
    "        tst_path = Path('data/test/')  \n",
    "        tst_path.mkdir(parents=True, exist_ok=True)\n",
    "        fn = Path('data/markup/220966 - 1.png')\n",
    "        img = np.asarray(PIL.Image.open(fn))\n",
    "        _json = json.load(open('data/markup/220966 - 1.json'))\n",
    "        mrk_img = self.draw_labels_cv(img, _json, radius=40) \n",
    "        show_img(mrk_img[:500,1000:1500,:], figsize = (10,10))\n",
    "        PIL.Image.fromarray(mrk_img.astype(np.uint8)).save(f'{tst_path}/{fn.stem}.jpg', quality=90) \n",
    "\n",
    "    ## \n",
    "    def find_prediction_blobs(self, img, CONF=0.5, radius=40, plot=False): \n",
    "        # region props seems to have region.max_intensity errors if no data not np.int \n",
    "        SCALE = 100\n",
    "        CONF *= SCALE\n",
    "        selem = disk(6)\n",
    "    #     img = filters.gaussian(img, sigma= 1 / 40, multichannel=True)\n",
    "        img = (img * (SCALE/img.max())).astype(np.int)\n",
    "        img[img[:,:,0]<CONF,0] = 0\n",
    "        img[img[:,:,1]<CONF,1] = 0\n",
    "    #     img[:,:,0] = img[:,:,0] > CONF\n",
    "    #     img[:,:,1] = img[:,:,1] > CONF\n",
    "        predictions = []\n",
    "    #     imgL = img[:,:,0].astype(np.int)\n",
    "    #     img[:,:,0] = closing(img[:,:,0], selem)\n",
    "    #     img[:,:,1] = closing(img[:,:,1], selem)\n",
    "    #     img[:,:,0] = opening(img[:,:,0], selem)\n",
    "    #     img[:,:,1] = opening(img[:,:,1], selem)\n",
    "\n",
    "        fill = (255,0,0)\n",
    "        label_image0 = label(img[:,:,0] > CONF)\n",
    "        label_image1 = label(img[:,:,1] > CONF)\n",
    "\n",
    "#         img = img.copy()  # helped with a cv error?\n",
    "        img = np.array(img) # helped with a cv error?\n",
    "        for region in regionprops(label_image0, img[:,:,0], cache=True):\n",
    "            if region.area > 500:\n",
    "                cx = int(region.centroid[1])\n",
    "                cy = int(region.centroid[0])\n",
    "#                 import pdb; pdb.set_trace()\n",
    "#                 cv2.rectangle(img, (cx - radius, cy - radius), (cx + radius, cy + radius), fill, 5)\n",
    "                predictions.append({\"label\": 'Strongyle', \"point\": [cx,cy], \"probability\": region.max_intensity.round(2)})  \n",
    "    #             print(' 0:', [cx,cy], 'area:',  region.area, \n",
    "    #                   'max',  region.max_intensity.round(2), \n",
    "    #                   'mean', region.mean_intensity.round(2))\n",
    "        fill = (0,255,0)\n",
    "        img = np.array(img) # helped with a cv error?\n",
    "        for region in regionprops(label_image1, img[:,:,1]):\n",
    "            if region.area > 500:\n",
    "                cx = int(region.centroid[1])\n",
    "                cy = int(region.centroid[0])\n",
    "#                 cv2.rectangle(img, (cx - radius, cy - radius), (cx + radius, cy + radius), fill, 5)\n",
    "                predictions.append({\"label\": 'Nematodirus',\"point\": [cx,cy], \"probability\": region.max_intensity.round(2)})\n",
    "    #             print(f' 1: area {region.area}, max intensity {region.max_intensity.round(5)}')\n",
    "    #         #     print(region.area)\n",
    "        if plot:\n",
    "            #   show_img(imglab, figsize = (15,15))\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            plt.subplot(121)\n",
    "            plt.imshow(label_image0, cmap='nipy_spectral')\n",
    "            #   plt.imshow(img[:,:,0] > CONF, cmap='nipy_spectral')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(122)\n",
    "            plt.imshow(label_image1, cmap='nipy_spectral')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        return predictions, img\n",
    "    def test_find_prediction_blobs(self ): \n",
    "    #     fn = 'data/markup/220966 - 1.png'\n",
    "        tst_path = Path('data/test/')\n",
    "        fn = Path('data/markup/221221 - 1.png')\n",
    "        print(f\"Testing: def test_find_prediction_blobs('{fn}'):\")\n",
    "        img = np.asarray(PIL.Image.open(fn))\n",
    "\n",
    "\n",
    "        anno_list, proc_img = self.find_prediction_blobs(img, plot=True)\n",
    "        print(\"Max value\", proc_img.max())\n",
    "        PIL.Image.fromarray(proc_img.astype(np.uint8)).save(f'{tst_path}/{fn.stem}.png') \n",
    "    #     print(anno_list)\n",
    "\n",
    "    ## Annotate the json file with predictions\n",
    "    def annotate_json(self, fn, annotations=None):\n",
    "        def add_anno(data, item):\n",
    "            r = 40\n",
    "            cx,cy = item['point']\n",
    "            pnt_list = [[cx-r,cy-r], [cx+r,cy+r]]\n",
    "\n",
    "            probability = str(item['probability']) if 'probability' in item else str(0)\n",
    "\n",
    "            if item['label'][:3]=='Str': \n",
    "                line_color = [255,0,0,127]\n",
    "                data['shapes'].append({\n",
    "                        \"label\": item['label'],\"line_color\": line_color, \"fill_color\": None,\n",
    "                        \"points\": pnt_list, \"shape_type\": \"circle\", 'probability': probability\n",
    "            })      \n",
    "\n",
    "            elif item['label'][:3]=='Nem': \n",
    "                line_color = [0,255,0,127]\n",
    "                data['shapes'].append({\n",
    "                        \"label\": item['label'],\"line_color\": line_color, \"fill_color\": None,\n",
    "                        \"points\": pnt_list, \"shape_type\": \"circle\", 'probability': probability\n",
    "                })\n",
    "            else:\n",
    "                print('Unknown label')\n",
    "\n",
    "        def add_annotations(data, annotations): \n",
    "            for item in annotations:\n",
    "                add_anno(data, item)\n",
    "\n",
    "        def del_circle_annotations(data):\n",
    "            to_del = [s for s,sh in enumerate(data['shapes']) if sh['shape_type']=='circle']\n",
    "            if len(to_del) > 0: \n",
    "                print(f'Deleting {len(to_del)} circle annotations')\n",
    "            for i in sorted(to_del, reverse=True):\n",
    "                del data['shapes'][i]        \n",
    "\n",
    "        data = json.load(open(fn))\n",
    "        del_circle_annotations(data)\n",
    "        add_annotations(data, annotations) \n",
    "        return data\n",
    "\n",
    "    def test_annotate_json(self):  \n",
    "      fn = 'data/markup/220966 - 1.png'\n",
    "      img = np.asarray(PIL.Image.open(fn))\n",
    "\n",
    "      predictions, _ = self.find_prediction_blobs(img, plot=False)\n",
    "      print(predictions)\n",
    "      data= self.annotate_json('data/subset/220966 - 1.json', predictions)\n",
    "      print(data)\n",
    "      with open('data/subset/220966 - 1.json', 'w') as outfile:\n",
    "        json.dump(data, outfile, ensure_ascii=False, indent=4)   \n",
    "\n",
    "    ## Unet Predict classes from a well image\n",
    "    def unet_predict_classes(self):\n",
    "        fn = 'data/subset/220967 - 1.json'\n",
    "        data = json.load(open(fn))\n",
    "\n",
    "        ## Infer Classes\n",
    "\n",
    "        img = open_image('data/subset/220972 - 1.jpg')\n",
    "\n",
    "        img = padImage_t(img)\n",
    "        tiles = cut_tiles_t(img)\n",
    "\n",
    "        n = len(tiles)\n",
    "        pred_class, pred_idx, outputs = [None]*n, [None]*n, [None]*n\n",
    "        for i, im in enumerate(tiles):\n",
    "          pc,pi,o = learn.predict(im)  \n",
    "          pred_class[i] = pc.px\n",
    "\n",
    "        vstack = lay_tiles_t(pred_class, TM=4, TN=4, pad=100)\n",
    "        Image(vstack).show(figsize = (10,10))\n",
    "\n",
    "    ## Infer Probabilities\n",
    "    def unet_predict_eggs(self, fn):\n",
    "      img = open_image(fn)\n",
    "\n",
    "      PAD = 100\n",
    "      TM, TN =4, 4\n",
    "      img = padImage_t(img, pad=PAD)\n",
    "      tiles = cut_tiles_t(img, TM=TM, TN=TN, pad=PAD)\n",
    "\n",
    "      outputs = []\n",
    "      for i, im in enumerate(tiles):\n",
    "        pc,pi,o = learn.predict(im)  \n",
    "        outputs.append(o)\n",
    "\n",
    "      vstack = lay_tiles_t(outputs, TM=TM, TN=TN, pad=PAD)\n",
    "      vstack[0,:,:] = vstack[1,:,:]\n",
    "      vstack[1,:,:] = vstack[2,:,:]\n",
    "      vstack[2,:,:] = 0\n",
    "    #   vstack[vstack<0.3] = 0\n",
    "      img = to_np(vstack).transpose(1,2,0)\n",
    "      return img\n",
    "\n",
    "\n",
    "    ### Generate prediction png file\n",
    "    # def predict_in_image(self, fn, CONF=0.3):\n",
    "    #   pred_img = unet_predict_eggs(fn)\n",
    "    #   predictions = mark_predictions(pred_img, CONF=CONF)\n",
    "    # #   print(predictions)\n",
    "    #   jdata= annotate_json(f'{img_path}/{fn.stem}.json', predictions)\n",
    "    # \n",
    "    #   mrk_img = np.asarray(PIL.Image.open(fn))\n",
    "    #   mrk_img = draw_labels_cv(mrk_img, jdata, radius=50)\n",
    "    #   return pred_img, mrk_img, jdata\n",
    "\n",
    "    # def markup_image(self, img, CONF=0.5):\n",
    "    #     predictions, _ = self.find_prediction_blobs(img, CONF=CONF)\n",
    "    #     #   print(predictions)\n",
    "    #     jdata= self.annotate_json(f'{self.img_path}/{fn.stem}.json', predictions)\n",
    "    # \n",
    "    #     mrk_img = np.asarray(PIL.Image.open(f'{img_path}/{fn.stem}.jpg'))\n",
    "    #     mrk_img = self.draw_labels_cv(mrk_img, jdata, radius=50)\n",
    "    #     return mrk_img, jdata\n",
    "    \n",
    "    def markup_all_images_dir(self, count='all', CONF=0.5):\n",
    "        fnames = sorted(get_files(self.mrk_path, '.png'))\n",
    "        if count.isdigit(): \n",
    "            fnames = fnames[:count]\n",
    "        print(f'Marking up {len(fnames)} images')\n",
    "\n",
    "        for n, fn in enumerate(fnames):\n",
    "#             print(fn, end=' ')\n",
    "            src_img = np.asarray(PIL.Image.open(fn))\n",
    "            # find blobs in png            mrk_img, jdata = self.markup_image(img) \n",
    "            predictions, _ = self.find_prediction_blobs(src_img, CONF=CONF)\n",
    "            print(len(predictions), end=', ')\n",
    "            if n % 20 == 0:\n",
    "              print(';')\n",
    "    \n",
    "            # annotate json\n",
    "            jdata= self.annotate_json(f'{self.img_path}/{fn.stem}.json', predictions)\n",
    "            with open(f'{self.mrk_path}/{fn.stem}.json', 'w') as outfile:\n",
    "                json.dump(jdata, outfile, ensure_ascii=False, indent=4)   \n",
    "            # mark up jpg\n",
    "            mrk_img = np.asarray(PIL.Image.open(f'{self.img_path}/{fn.stem}.jpg'))\n",
    "            mrk_img = self.draw_labels_cv(mrk_img, jdata, radius=50)\n",
    "            PIL.Image.fromarray(mrk_img.astype(np.uint8)).save(f'{self.mrk_path}/{fn.stem}.jpg', quality=90)  \n",
    "\n",
    "        return mrk_img\n",
    "    \n",
    "\n",
    "\n",
    "    def calc_stats_row(self, jdata, radius=30):\n",
    "        human = []\n",
    "        machine = []\n",
    "        for s,sh in enumerate(jdata['shapes']):\n",
    "            ave = np.mean(np.asarray(sh[\"points\"]),axis=0).tolist()\n",
    "            if sh['shape_type'] == 'rectangle':\n",
    "                human.append(ave)\n",
    "            elif sh['shape_type'] == 'circle':\n",
    "                machine.append(ave)\n",
    "            else:\n",
    "                print(\"unknown label\", data[\"imagePath\"])\n",
    "\n",
    "        if (len(human) > 0) and (len(machine) > 0):\n",
    "            dist = distance.cdist(human, machine, 'euclidean')\n",
    "            n_human, n_AI, n_match = len(human), len(machine), (np.min(dist, axis=1) < radius).sum()\n",
    "        else:\n",
    "            n_human, n_AI, n_match = len(human), len(machine), 0\n",
    "\n",
    "        row = {\n",
    "            'File': jdata[\"imagePath\"],\n",
    "            'Num Human': n_human, \n",
    "            'Num AI': n_AI, \n",
    "            'Matched': n_match, \n",
    "            'AI: Un-matched': n_AI - n_match, \n",
    "            'AI: Missed Eggs': n_human - n_match\n",
    "        }\n",
    "\n",
    "        return row\n",
    "\n",
    "    def calc_stats_table(self):\n",
    "        # img_path = Path('data/markup')\n",
    "    #     mrk_path = Path('data/testimages-markup/')\n",
    "\n",
    "        fnames = sorted(get_files(self.mrk_path, '.json'))\n",
    "\n",
    "        df = DataFrame (columns = ['File', 'Num Human','Num AI', 'Matched', 'AI: Un-matched', 'AI: Missed Eggs'])\n",
    "        fnames = fnames\n",
    "        for fn in fnames:\n",
    "            data = json.load(open(fn))\n",
    "            row = self.calc_stats_row(data, radius=30)\n",
    "            df = df.append(row, ignore_index=True)\n",
    "\n",
    "        for col in range(1, len(df.columns)):\n",
    "            df.iloc[:,col] = pd.to_numeric(df.iloc[:,col])\n",
    "\n",
    "        _sum = df.sum(axis = 0, skipna=True, numeric_only=True).rename('Total') \n",
    "        _mean = df.mean(axis = 0, skipna=True, numeric_only=True).rename('Mean') \n",
    "\n",
    "        # df= df.append(df.sum(axis = 0, skipna=True, numeric_only=True).rename('Total')) \n",
    "\n",
    "        # df=df.append(df.mean(axis = 0, skipna=True, numeric_only=True).rename('Mean'))    \n",
    "        df = df.append(_mean).append(_sum)\n",
    "        return df\n",
    "    def plot_piechart(self, df):\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\n",
    "        explode = (0.1, 0)  # explode 1st slice\n",
    "        labels = 'Matched Eggs', 'AI: Missed Eggs' \n",
    "        sizes = [df.at['Total','Matched'], df.at['Total','AI: Missed Eggs']]\n",
    "        axes[0].pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "        labels = 'Matched Eggs', 'AI: Predictions not Matched' \n",
    "        sizes = [df.at['Total','Matched'], df.at['Total','AI: Un-matched']]\n",
    "        axes[1].pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "        plt.tight_layout(pad=0.0)\n",
    "# pi = AnalysePredictions()\n",
    "# print(\"Start tests:\")\n",
    "# pi.test_annotate_json()\n",
    "# ii.test_draw_labels_cv()\n",
    "# ii.test_find_prediction_blobs()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def find_prediction_blobs( img, CONF=0.3, radius=40, plot=False): \n",
    "    # region props seems to have region.max_intensity errors if no data not np.int \n",
    "    SCALE = 100\n",
    "    CONF *= SCALE\n",
    "    \n",
    "    img = (img * (SCALE/img.max())).astype(np.int)\n",
    "    img[img<CONF] = 0\n",
    "    predictions = []\n",
    "    label_image = label(img > CONF)\n",
    "    \n",
    "    #         img = np.array(img) # helped with a cv error?\n",
    "    for region in regionprops(label_image, img, cache=True):\n",
    "        if region.area > 100:\n",
    "            cx = int(region.centroid[1])\n",
    "            cy = int(region.centroid[0])\n",
    "            predictions.append({\"label\": 'Strongyle', \"point\": [cx,cy], \"probability\": region.max_intensity.round(2)})  \n",
    "    \n",
    "    return predictions, img\n",
    "\n",
    "\n",
    "def annotate_json(fn, annotations=None):\n",
    "    'Annotate the json file with predictions'\n",
    "    def add_anno(data, item):\n",
    "        r = 40\n",
    "        cx,cy = item['point']\n",
    "        pnt_list = [[cx-r,cy-r], [cx+r,cy+r]]\n",
    "\n",
    "        probability = str(item['probability']) if 'probability' in item else str(0)\n",
    "\n",
    "        if item['label'][:3]=='Str': \n",
    "            line_color = [255,0,0,127]\n",
    "            data['shapes'].append({\n",
    "                    \"label\": item['label'],\"line_color\": line_color, \"fill_color\": None,\n",
    "                    \"points\": pnt_list, \"shape_type\": \"circle\", 'probability': probability\n",
    "        })      \n",
    "\n",
    "        elif item['label'][:3]=='Nem': \n",
    "            line_color = [0,255,0,127]\n",
    "            data['shapes'].append({\n",
    "                    \"label\": item['label'],\"line_color\": line_color, \"fill_color\": None,\n",
    "                    \"points\": pnt_list, \"shape_type\": \"circle\", 'probability': probability\n",
    "            })\n",
    "        else:\n",
    "            print('Unknown label')\n",
    "\n",
    "    def add_annotations(data, annotations): \n",
    "        for item in annotations:\n",
    "            add_anno(data, item)\n",
    "\n",
    "    def del_circle_annotations(data):\n",
    "        to_del = [s for s,sh in enumerate(data['shapes']) if sh['shape_type']=='circle']\n",
    "        if len(to_del) > 0: \n",
    "            print(f'Deleting {len(to_del)} circle annotations')\n",
    "        for i in sorted(to_del, reverse=True):\n",
    "            del data['shapes'][i]        \n",
    "\n",
    "    data = json.load(open(fn))\n",
    "    # del_circle_annotations(data)\n",
    "    add_annotations(data, annotations) \n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'Strongyle', 'point': [768, 177], 'probability': 69},\n {'label': 'Strongyle', 'point': [313, 336], 'probability': 100},\n {'label': 'Strongyle', 'point': [288, 650], 'probability': 99},\n {'label': 'Strongyle', 'point': [770, 685], 'probability': 83}]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds\n",
    "predictions, img = find_prediction_blobs( to_np(preds['Fluke_Liver']))\n",
    "show_img(img)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2.530080e-03, 2.290793e-03, 9.769002e-04, 2.425112e-04, ..., 2.832348e-03, 4.224682e-03, 4.696379e-03,\n        8.341388e-03],\n       [7.502590e-04, 8.338390e-04, 7.248910e-04, 1.502040e-04, ..., 2.461558e-03, 4.082000e-03, 4.715894e-03,\n        6.574791e-03],\n       [3.527227e-04, 3.848545e-04, 6.420778e-04, 1.822658e-04, ..., 2.942182e-03, 5.112409e-03, 4.840271e-03,\n        2.247877e-03],\n       [2.976774e-04, 3.085131e-04, 5.771366e-04, 2.293458e-04, ..., 1.864430e-03, 3.432195e-03, 2.624897e-03,\n        7.026473e-04],\n       ...,\n       [1.984489e-03, 2.766282e-03, 1.858092e-03, 5.149026e-04, ..., 2.815052e-07, 9.348914e-07, 2.402427e-06,\n        2.821103e-06],\n       [3.302467e-03, 3.153032e-03, 2.695337e-03, 1.164194e-03, ..., 3.090470e-06, 7.436967e-06, 1.892944e-05,\n        2.077264e-05],\n       [1.551290e-03, 7.544339e-04, 1.294823e-03, 6.098641e-04, ..., 5.507753e-06, 1.009877e-05, 1.959550e-05,\n        5.298379e-05],\n       [1.568920e-03, 7.218754e-04, 1.271034e-03, 7.781513e-04, ..., 1.883820e-05, 2.519766e-05, 8.562210e-05,\n        5.039946e-04]], dtype=float32)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "to_np(preds['Fluke_Liver'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Background torch.Size([800, 816])\nFluke_Liver torch.Size([800, 816])\nFluke_Rumen torch.Size([800, 816])\nOther torch.Size([800, 816])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "img_path = Path(dirs.train)\n",
    "mrk_path = Path('../testdata_2/Fullsize/markup')  \n",
    "mrk_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fnames = sorted(get_image_files(img_path))\n",
    "classes = ['Background', 'Fluke_Liver', 'Fluke_Rumen', 'Other']\n",
    "\n",
    "preds = run_prediction(learn, fnames[1], classes=classes, tile=False, filesavedir=mrk_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def save_png(img:np.ndarray, fn, cmap:str='hot'):\n",
    "    # img = PIL.Image.fromarray(to_np(img*255).astype(np.uint8))\n",
    "    # img = img.convert('P', palette=PIL.Image.ADAPTIVE, colors=256)\n",
    "    # img.save(fn)\n",
    "    # Get the color map by name:\n",
    "    cm = plt.get_cmap(cmap)\n",
    "    colored_image = cm(img)\n",
    "    PIL.Image.fromarray((colored_image * 255).astype(np.uint8)).save(fn)   \n",
    "\n",
    "def save_png_p(img:np.ndarray, fn, cmap:str='hot', num_colors=256):\n",
    "    assert num_colors > 0 and num_colors <= 256, 'num_colors must be in range 0 to 256'\n",
    "    cm = plt.get_cmap(cmap)\n",
    "    palette = np.ones((256,3),dtype=np.uint8)*128\n",
    "    pal = (cm(np.arange(num_colors))*255).astype(np.uint8)[:,:3]\n",
    "    palette[:num_colors,:] = pal\n",
    "    img = PIL.Image.fromarray((img*255).astype(np.uint8), mode='P')\n",
    "    img.putpalette(palette)\n",
    "    img.save(fn)\n",
    "\n",
    "raw_pred  = to_np(preds['Fluke_Liver'])\n",
    "save_png_p(raw_pred, f'{mrk_path}/{\"111test\"}.png', cmap='tab10', num_colors=10)\n",
    "save_png_p(raw_pred, f'{mrk_path}/{\"112test\"}.png')\n",
    "save_png_p(raw_pred, f'{mrk_path}/{\"113test\"}.png', cmap='Dark2', num_colors=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "palette = np.arange(256)\n",
    "cm = plt.get_cmap('hot')\n",
    "palette = (cm(np.arange(256))*255).astype(np.uint8)[:,:3]\n",
    "palette"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[colormaps](https://matplotlib.org/2.0.1/examples/color/colormaps_reference.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#\n",
    "raw_pred  = preds['Fluke_Liver']\n",
    "save_png(raw_pred, f'{mrk_path}/{\"111test\"}.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "raw",
   "source": [
    "_pred  = preds['Fluke_Liver']\n",
    "import matplotlib.pyplot as plt\n",
    "lbl_pil = PIL.Image.fromarray(to_np(raw_pred*255).astype(np.uint8))\n",
    "lbl_pil = lbl_pil.convert('P', palette=PIL.Image.ADAPTIVE, colors=256)\n",
    "lbl_pil.save(f'{mrk_path}/{\"111\"}.png')\n",
    "# Get the color map by name:\n",
    "cm = plt.get_cmap('hot')\n",
    "\n",
    "# Apply the colormap like a function to any array:\n",
    "colored_image = cm(to_np(raw_pred))\n",
    "\n",
    "# Obtain a 4-channel image (R,G,B,A) in float [0, 1]\n",
    "# But we want to convert to RGB in uint8 and save it:\n",
    "PIL.Image.fromarray((colored_image * 255).astype(np.uint8)).save(f'{mrk_path}/{\"111test\"}.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mrk_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seq = np.arange(256)\n",
    "cm = plt.get_cmap('hot')\n",
    "AAcolored_image = cm(seq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "palette = np.arange(10)\n",
    "cm = plt.get_cmap('tab10')\n",
    "palette = (cm(np.arange(10))*255).astype(np.uint8)[:,:3]\n",
    "palette"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}