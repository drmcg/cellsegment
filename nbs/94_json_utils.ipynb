{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# JSON utilities\n",
    "> Functions that prepare label files and split the data into train validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "# default_exp json_utils\n",
    "from nbdev.showdoc import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# hide\n",
    "# hidden imports\n",
    "# from  cellsegment.json_utils import *   #hide this otherwise recurseive "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "import random\n",
    "from  cellsegment.core import *\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "import pandas\n",
    "from fastai.vision import get_image_files, parallel, partial, PIL, Path, get_files\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def createjson(fn='', offset=0):\n",
    "    'create a Labelme compatable json file'\n",
    "    data = {\n",
    "        'version': '3.13.1',\n",
    "        'flags': {},\n",
    "        'shapes': [],\n",
    "        'lineColor': [0, 255, 0, 255],\n",
    "        'fillColor': [255, 255, 0, 20],\n",
    "        'imagePath': fn,\n",
    "        'offset': offset,\n",
    "        'imageData': None,\n",
    "        'imageHeight': 2464,\n",
    "        'imageWidth': 2464}\n",
    "    return data\n",
    "\n",
    "TEST_JSON_STRING = \"\"\"\n",
    "{\n",
    "  \"version\": \"3.13.1\",\n",
    "  \"flags\": {},\n",
    "  \"shapes\": [\n",
    "    {\n",
    "      \"label\": \"Liver Fluke\",\n",
    "      \"line_color\": [0, 0, 255, 127],\n",
    "      \"fill_color\": [0, 0, 255, 127],\n",
    "      \"points\": [\n",
    "        [622.4545454545455, 523.8484848484848], [642.4545454545455, 543.8484848484848]\n",
    "      ],\n",
    "      \"shape_type\": \"circle\",\n",
    "      \"flags\": {}\n",
    "    }\n",
    "  ],\n",
    "  \"lineColor\": [0, 255, 0, 255],\n",
    "  \"fillColor\": [255, 255, 0, 20],\n",
    "  \"imagePath\": \"235443 - 1.jpg\",\n",
    "  \"imageData\": null,\n",
    "  \"imageHeight\": 813,\n",
    "  \"imageWidth\": 830,\n",
    "  \"offset\": 0\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see lableme at https://github.com/wkentaro/labelme/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def annotate_json(data, shape_type='circle', points=None):\n",
    "    # Annotate the json file with list of points\n",
    "    assert shape_type == 'point' or shape_type == 'circle' or shape_type == 'rectangle'\n",
    "\n",
    "    def add_anno(data, item):\n",
    "        cx, cy = item['point']\n",
    "        pnt_list = []\n",
    "        if shape_type == 'point':\n",
    "            pnt_list = [[cx, cy]]\n",
    "        elif shape_type == 'rectangle':  # bounding points\n",
    "            r = 40\n",
    "            pnt_list = [[cx - r, cy - r], [cx + r, cy + r]]\n",
    "        elif shape_type == 'circle':   # center & radius\n",
    "            r = 20\n",
    "            pnt_list = [[cx, cy], [cx + r, cy + r]]\n",
    "\n",
    "        probability = str(item['probability']) if 'probability' in item else str(0)\n",
    "\n",
    "        if item['label'] == 1:\n",
    "            line_color = [255, 0, 0, 127]\n",
    "            data['shapes'].append({\n",
    "                \"label\": str(item['label']), \"line_color\": [255, 0, 0, 127], \"fill_color\": [255, 0, 0, 127],\n",
    "                \"points\": pnt_list, \"shape_type\": shape_type, 'probability': probability\n",
    "            })\n",
    "\n",
    "        elif item['label'] == 2:\n",
    "            line_color = [0, 255, 0, 127]\n",
    "            data['shapes'].append({\n",
    "                \"label\": str(item['label']), \"line_color\": [0, 255, 0, 127], \"fill_color\": [0, 255, 0, 127],\n",
    "                \"points\": pnt_list, \"shape_type\": shape_type, 'probability': probability\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            line_color = [0, 0, 255, 127]\n",
    "            data['shapes'].append({\n",
    "                \"label\": str(item['label']), \"line_color\": [0, 0, 255, 127], \"fill_color\": [0, 0, 255, 127],\n",
    "                \"points\": pnt_list, \"shape_type\": shape_type, 'probability': probability\n",
    "            })\n",
    "\n",
    "    def add_annotations(data, points):\n",
    "        for item in points:\n",
    "            add_anno(data, item)\n",
    "\n",
    "    add_annotations(data, points)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def create_json_from_CSV(csv_fn, load_jpg_fn, offset=0, height=0, width=0):\n",
    "    # Annotate the json file with predictions\n",
    "    data = {\n",
    "        'version': '3.13.1',\n",
    "        'flags': {},\n",
    "        'shapes': [],\n",
    "        'lineColor': [0, 255, 0, 255],\n",
    "        'fillColor': [255, 255, 0, 20],\n",
    "        'imagePath': load_jpg_fn,\n",
    "        'offset': offset,\n",
    "        'imageData': None,\n",
    "        'imageHeight': height,\n",
    "        'imageWidth': width}\n",
    "\n",
    "    # species_name = ['Nematodirus', 'Strongyle', 'other']\n",
    "\n",
    "    egg_centers = []\n",
    "    with open(csv_fn, mode='r') as f:\n",
    "        line_count = 0\n",
    "        for line in f:\n",
    "            row, col, species = [int(x) for x in line.split(',')]\n",
    "            egg_centers.append({\"label\": species, \"particleType\": species, \"point\": [row, col]})\n",
    "            line_count += 1\n",
    "\n",
    "    data = annotate_json(data, points=egg_centers)\n",
    "    data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def csv_to_json_dir(src_path, dest_path, number_files='all'):\n",
    "    \"\"\" Convert an entire directory of Techion CSV files to JSON files. Store in the dest directory\n",
    "    CSV format is x,y,species_number\n",
    "    1383,1571,2\n",
    "    1687,1822,1\n",
    "    2036,1327,1\n",
    "    \"\"\"\n",
    "    print('Converting an entire directory of Techion CSV files to JSON files')\n",
    "    fnames_csv = sorted(get_files(src_path, extensions=['.csv']))\n",
    "    fnames_jpg = sorted(get_files(src_path, extensions=['.jpg']))\n",
    "    if isinstance(number_files, int):\n",
    "        fnames_csv = fnames_csv[:number_files]\n",
    "        fnames_jpg = fnames_jpg[:number_files]\n",
    "    print('Number of csv & jpg files to convert', len(fnames_csv), len(fnames_jpg))\n",
    "\n",
    "    Path(dest_path).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"src_path {src_path}\")\n",
    "    print(f\"dest_path {dest_path}\")\n",
    "\n",
    "    for i,fn in enumerate(fnames_csv):\n",
    "        parent = Path(fn).parents[0]\n",
    "        name = Path(fn).name.split('.')[0]\n",
    "        jpg_fn = f\"{parent}/{name}.jpg\"\n",
    "        json_fn = f\"{parent}/{name}.json\"\n",
    "\n",
    "        if Path(jpg_fn).is_file():\n",
    "            img = PIL.Image.open(jpg_fn)\n",
    "            data = create_json_from_CSV(fn, Path(jpg_fn).name, height=img.size[1], width=img.size[0])\n",
    "            with open(json_fn, 'w') as outfile:\n",
    "                # json.dump(data, outfile, indent=2)\n",
    "                # print(f'Saving File {json_fn}')\n",
    "                json.dump(data, outfile, ensure_ascii=False, indent=4)\n",
    "                progress_bar(i+1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def resize_json_file(fn, scale=1, offset=0):\n",
    "    data = json.load(open(fn))\n",
    "\n",
    "    for s, sh in enumerate(data['shapes']):\n",
    "        for p, pnt in enumerate(sh[\"points\"]):\n",
    "            data['shapes'][s]['points'][p][0] = round(data['shapes'][s]['points'][p][0] * scale)\n",
    "            data['shapes'][s]['points'][p][1] = round(data['shapes'][s]['points'][p][1] * scale)\n",
    "            data['shapes'][s]['points'][p][0] = data['shapes'][s]['points'][p][0] - offset\n",
    "    data['imageData'] = None\n",
    "    data['offset'] = offset\n",
    "    data['scale'] = scale\n",
    "    data['imageWidth'] = int (data['imageWidth'] * scale)\n",
    "    data['imageHeight'] = int (data['imageHeight'] * scale)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def resize_json_dir(file_data, src_path, dest_path, number_files='all', height=800):\n",
    "    \"\"\"\n",
    "    Resize src_path directory of JSON files and store in dest_path directory\n",
    "    There needs to be resized jpg files in the dest_path directory.\n",
    "    An example is  226260 - 1|0.436047|221|.jpg  where |0.436047|221| marks the factor and offset factors to apply\n",
    "    :param src_path: Source path where json files are\n",
    "    :param dest_path: Destination path to store resized json files\n",
    "    :param number_files: Number of json files to process, leave empty for all files in directory\n",
    "    :return: number of file processed\n",
    "    \"\"\"\n",
    "    df = pandas.read_csv(file_data, index_col=0)\n",
    "    __number_files = df.shape[0]\n",
    "\n",
    "    print(f'Number of JSON files: {__number_files}, Number to resize: {number_files}')\n",
    "    Path(dest_path).mkdir(parents=True, exist_ok=True)\n",
    "    if isinstance(number_files, int):\n",
    "        __number_files = number_files\n",
    "\n",
    "    for i in range(__number_files):\n",
    "        f_stem = df.loc[i,'Name'].split('.')[0]\n",
    "        scale = float(height) / df.loc[i,'Height']\n",
    "        offset = 0\n",
    "        data = resize_json_file(f'{src_path}/{f_stem}.json', scale=float(scale), offset=int(offset))\n",
    "        data['imagePath'] = df.loc[i,'Name']\n",
    "        with open(f'{dest_path}/{f_stem}.json', 'w') as outfile:\n",
    "            json.dump(data, outfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "        progress_bar(i + 1, 50)\n",
    "    print('')\n",
    "    print(i+1, ' json files processed')\n",
    "    return i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> Test create_json_from_CSV()\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c64042ba4e79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mjson_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_json_from_CSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nbs_test_data/235443 - 1.jpg.points.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nbs_test_data/235443 - 1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprettyjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prettyjson' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'prettyjson' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "from json import JSONEncoder\n",
    "json_object = create_json_from_CSV('nbs_test_data/235443 - 1.jpg.points.csv', 'nbs_test_data/235443 - 1.jpg')\n",
    "\n",
    "b = prettyjson(json_object)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "# https://stackoverflow.com/a/56497521/104668\n",
    "\n",
    "def prettyjson(obj, indent=2, maxlinelength=80):\n",
    "    \"\"\"\n",
    "    Renders JSON content with indentation and line splits/concatenations to fit maxlinelength.\n",
    "    Only dicts, lists and basic types are supported\n",
    "    - https://github.com/andy-gh/prettyjson\n",
    "    - https://stackoverflow.com/a/56497521/104668\n",
    "    \"\"\"\n",
    "\n",
    "    items, _ = getsubitems(obj, itemkey=\"\", islast=True, maxlinelength=maxlinelength, level=0)\n",
    "    return indentitems(items, indent, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import types\n",
    "def getsubitems(obj, itemkey, islast, maxlinelength, level):\n",
    "    items = []\n",
    "    is_inline = True      # at first, assume we can concatenate the inner tokens into one line\n",
    "\n",
    "    isdict = isinstance(obj, dict)\n",
    "    islist = isinstance(obj, list)\n",
    "    istuple = isinstance(obj, tuple)\n",
    "    isbasictype = not (isdict or islist or istuple)\n",
    "\n",
    "    # build json content as a list of strings or child lists\n",
    "    if isbasictype:\n",
    "        # render basic type\n",
    "        keyseparator  = \"\" if itemkey == \"\" else \": \"\n",
    "        itemseparator = \"\" if islast else \",\"\n",
    "        items.append(itemkey + keyseparator + basictype2str(obj) + itemseparator)\n",
    "\n",
    "    else:\n",
    "        # render lists/dicts/tuples\n",
    "        if isdict:    opening, closing, keys = (\"{\", \"}\", iter(obj.keys()))\n",
    "        elif islist:  opening, closing, keys = (\"[\", \"]\", range(0, len(obj)))\n",
    "        elif istuple: opening, closing, keys = (\"[\", \"]\", range(0, len(obj)))    # tuples are converted into json arrays\n",
    "\n",
    "        if itemkey != \"\": opening = itemkey + \": \" + opening\n",
    "        if not islast: closing += \",\"\n",
    "\n",
    "        count = 0\n",
    "        itemkey = \"\"\n",
    "        subitems = []\n",
    "\n",
    "        # get the list of inner tokens\n",
    "        for (i, k) in enumerate(keys):\n",
    "            islast_ = i == len(obj)-1\n",
    "            itemkey_ = \"\"\n",
    "            if isdict: itemkey_ = basictype2str(k)\n",
    "            inner, is_inner_inline = getsubitems(obj[k], itemkey_, islast_, maxlinelength, level+1)\n",
    "            subitems.extend(inner)                        # inner can be a string or a list\n",
    "            is_inline = is_inline and is_inner_inline     # if a child couldn't be rendered inline, then we are not able either\n",
    "\n",
    "        # fit inner tokens into one or multiple lines, each no longer than maxlinelength\n",
    "        if is_inline:\n",
    "            multiline = True\n",
    "\n",
    "            # in Multi-line mode items of a list/dict/tuple can be rendered in multiple lines if they don't fit on one.\n",
    "            # suitable for large lists holding data that's not manually editable.\n",
    "\n",
    "            # in Single-line mode items are rendered inline if all fit in one line, otherwise each is rendered in a separate line.\n",
    "            # suitable for smaller lists or dicts where manual editing of individual items is preferred.\n",
    "\n",
    "            # this logic may need to be customized based on visualization requirements:\n",
    "            if (isdict): multiline = False\n",
    "            if (islist): multiline = True\n",
    "\n",
    "            if (multiline):\n",
    "                lines = []\n",
    "                current_line = \"\"\n",
    "                current_index = 0\n",
    "\n",
    "                for (i, item) in enumerate(subitems):\n",
    "                    item_text = item\n",
    "                    if i < len(inner)-1: item_text = item + \",\"\n",
    "\n",
    "                    if len (current_line) > 0:\n",
    "                        try_inline = current_line + \" \" + item_text\n",
    "                    else:\n",
    "                        try_inline = item_text\n",
    "\n",
    "                    if (len(try_inline) > maxlinelength):\n",
    "                        # push the current line to the list if maxlinelength is reached\n",
    "                        if len(current_line) > 0: lines.append(current_line)\n",
    "                        current_line = item_text\n",
    "                    else:\n",
    "                        # keep fitting all to one line if still below maxlinelength\n",
    "                        current_line = try_inline\n",
    "\n",
    "                    # Push the remainder of the content if end of list is reached\n",
    "                    if (i == len (subitems)-1): lines.append(current_line)\n",
    "\n",
    "                subitems = lines\n",
    "                if len(subitems) > 1: is_inline = False\n",
    "            else: # single-line mode\n",
    "                totallength = len(subitems)-1   # spaces between items\n",
    "                for item in subitems: totallength += len(item)\n",
    "                if (totallength <= maxlinelength):\n",
    "                    str = \"\"\n",
    "                    for item in subitems: str += item + \" \"  # insert space between items, comma is already there\n",
    "                    subitems = [ str.strip() ]               # wrap concatenated content in a new list\n",
    "                else:\n",
    "                    is_inline = False\n",
    "\n",
    "\n",
    "        # attempt to render the outer brackets + inner tokens in one line\n",
    "        if is_inline:\n",
    "            item_text = \"\"\n",
    "            if len(subitems) > 0: item_text = subitems[0]\n",
    "            if len(opening) + len(item_text) + len(closing) <= maxlinelength:\n",
    "                items.append(opening + item_text + closing)\n",
    "            else:\n",
    "                is_inline = False\n",
    "\n",
    "        # if inner tokens are rendered in multiple lines already, then the outer brackets remain in separate lines\n",
    "        if not is_inline:\n",
    "            items.append(opening)       # opening brackets\n",
    "            items.append(subitems)      # Append children to parent list as a nested list\n",
    "            items.append(closing)       # closing brackets\n",
    "\n",
    "    return items, is_inline\n",
    "\n",
    "\n",
    "def basictype2str(obj):\n",
    "    if isinstance (obj, str):\n",
    "        strobj = \"\\\"\" + str(obj) + \"\\\"\"\n",
    "    elif isinstance(obj, bool):\n",
    "        strobj = { True: \"true\", False: \"false\" }[obj]\n",
    "    else:\n",
    "        strobj = str(obj)\n",
    "    return strobj\n",
    "\n",
    "\n",
    "def indentitems(items, indent, level):\n",
    "    \"\"\"Recursively traverses the list of json lines, adds indentation based on the current depth\"\"\"\n",
    "    res = \"\"\n",
    "    indentstr = \" \" * (indent * level)\n",
    "    for (i, item) in enumerate(items):\n",
    "        if isinstance(item, list):\n",
    "            res += indentitems(item, indent, level+1)\n",
    "        else:\n",
    "            islast = (i==len(items)-1)\n",
    "            # no new line character after the last rendered line\n",
    "            if level==0 and islast:\n",
    "                res += indentstr + item\n",
    "            else:\n",
    "                res += indentstr + item + \"\\n\"\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}